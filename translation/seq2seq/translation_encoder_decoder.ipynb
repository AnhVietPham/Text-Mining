{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNQkv7W3j/7M6nUDIX9dGpo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnhVietPham/Text-Mining/blob/main/translation/seq2seq/translation_encoder_decoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUW6U_Vrt9zq",
        "outputId": "78fe67c0-658e-405a-838a-2b790a35f843"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "b6-SeKQXqrlx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "MAX_LENGTH = 20"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Lang:\n",
        "    def __init__(self):\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: 'S0S', 1: 'EOS'}\n",
        "        self.n_words = 2\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "metadata": {
        "id": "9PtJh5-5q1i9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_sentence(df, lang):\n",
        "    sentence = df[lang].str.lower()\n",
        "    sentence = sentence.str.normalize('NFD')\n",
        "    sentence = sentence.str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "FNZnb57zq69C"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_sentence(df, lang1, lang2):\n",
        "    sentence1 = normalize_sentence(df, lang1)\n",
        "    sentence2 = normalize_sentence(df, lang2)\n",
        "    return sentence1, sentence2"
      ],
      "metadata": {
        "id": "6VxICBjzq7wa"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(loc, lang1, lang2, des):\n",
        "    df = pd.read_csv(loc, delimiter='\\t', header=None, names=[lang1, lang2, des])\n",
        "    return df"
      ],
      "metadata": {
        "id": "Gf9yokHJq-W5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data(lang1, lang2):\n",
        "    df = read_file('/content/drive/MyDrive/Luận Văn Thạc Sĩ/translation/data/vie-eng/%s-%s.txt' % (lang1, lang2),\n",
        "                   lang1, lang2, \"des\")\n",
        "    print(\"Read %s sentence pairs\" % len(df))\n",
        "    sentence1, sentence2 = read_sentence(df, lang1, lang2)\n",
        "\n",
        "    source = Lang()\n",
        "    target = Lang()\n",
        "    pairs = []\n",
        "    for i in range(len(df)):\n",
        "        if len(sentence1[i].split(' ')) < MAX_LENGTH and len(sentence2[i].split(' ')) < MAX_LENGTH:\n",
        "            full = [sentence1[i], sentence2[i]]\n",
        "            source.addSentence(sentence1[i])\n",
        "            target.addSentence(sentence2[i])\n",
        "            pairs.append(full)\n",
        "\n",
        "    return source, target, pairs"
      ],
      "metadata": {
        "id": "2HC4kWLsrBDb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n",
        "\n",
        "def tensorsFromPair(input_lang, output_lang, pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "s-rX9clvrFxH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, embbed_dim, num_layers):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.embbed_dim = embbed_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, self.embbed_dim)\n",
        "\n",
        "        self.gru = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.embedding(src).view(1, 1, -1)\n",
        "        outputs, hidden = self.gru(embedded)\n",
        "        return outputs, hidden"
      ],
      "metadata": {
        "id": "mNj0KRU2rGgc"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, hidden_dim, embbed_dim, num_layers):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embbed_dim = embbed_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(output_dim, self.embbed_dim)\n",
        "        self.gru = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
        "        self.out = nn.Linear(self.hidden_dim, output_dim)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        input = input.view(1, -1)\n",
        "        embedded = F.relu(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        prediction = self.softmax(self.out(output[0]))\n",
        "        return prediction, hidden"
      ],
      "metadata": {
        "id": "QMVN6QzArLHh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, MAX_LENGTH=MAX_LENGTH):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
        "        input_length = source.size(0)\n",
        "        batch_size = target.shape[1]\n",
        "        target_length = target.shape[0]\n",
        "        vocab_size = self.decoder.output_dim\n",
        "\n",
        "        outputs = torch.zeros(target_length, batch_size, vocab_size)\n",
        "\n",
        "        for i in range(input_length):\n",
        "            encoder_output, encoder_hidden = self.encoder(source[i])\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_input = torch.tensor([SOS_token])\n",
        "\n",
        "        for t in range(target_length):\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "            outputs[t] = decoder_output\n",
        "            teach_force = random.random() < teacher_forcing_ratio\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            input = (target[t] if teach_force else topi)\n",
        "            if (teach_force == False and input.item() == EOS_token):\n",
        "                break\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "sUutHPG7rOB_"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clacModel(model, input_tensor, target_tensor, model_optimizer, criterion):\n",
        "    model_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    loss = 0\n",
        "    epoch_loss = 0\n",
        "    output = model(input_tensor, target_tensor)\n",
        "    num_iter = output.size(0)\n",
        "\n",
        "    for ot in range(num_iter):\n",
        "        loss += criterion(output[ot], target_tensor[ot])\n",
        "    loss.backward()\n",
        "    model_optimizer.step()\n",
        "    epoch_loss = loss.item() / num_iter\n",
        "    return epoch_loss"
      ],
      "metadata": {
        "id": "BLcuKeEOrOIA"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainModel(model, source, target, pairs, num_iteration=20000):\n",
        "    model.train()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "    criterion = nn.NLLLoss()\n",
        "    total_loss_iterations = 0\n",
        "    training_pairs = [tensorsFromPair(source, target, random.choice(pairs)) for i in range(num_iteration)]\n",
        "\n",
        "    for iter in range(1, num_iteration + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = clacModel(model, input_tensor, target_tensor, optimizer, criterion)\n",
        "        total_loss_iterations += loss\n",
        "\n",
        "        if iter % 5000 == 0:\n",
        "            avarge_loss = total_loss_iterations / 5000\n",
        "            total_loss_iterations = 0\n",
        "            print('%d %.4f' % (iter, avarge_loss))\n",
        "    torch.save(model.state_dict(), 'avptraning.pt')\n",
        "    return model"
      ],
      "metadata": {
        "id": "MgSnUgh3rVIF"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, input_lang, output_lang, sentences, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentences[0])\n",
        "        output_tensor = tensorFromSentence(output_lang, sentences[1])\n",
        "\n",
        "        decoded_words = []\n",
        "        output = model(input_tensor, output_tensor)\n",
        "\n",
        "        for ot in range(output.size(0)):\n",
        "            topv, topi = output[ot].topk(1)\n",
        "\n",
        "            if topi[0].item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi[0].item()])\n",
        "    return decoded_words"
      ],
      "metadata": {
        "id": "yn57UyjFrZFm"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateRandomly(model, source, target, pairs, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('source {}'.format(pair[0]))\n",
        "        print('target {}'.format(pair[1]))\n",
        "        output_words = evaluate(model, source, target, pair)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('Predicted {}'.format(output_sentence))"
      ],
      "metadata": {
        "id": "i0IhWtsMrbbN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lang1 = 'eng'\n",
        "lang2 = 'vie'\n",
        "source, target, pairs = process_data(lang1, lang2)\n",
        "randomize = random.choice(pairs)\n",
        "print('Random sentence {}'.format(randomize))\n",
        "\n",
        "input_size = source.n_words\n",
        "out_size = target.n_words\n",
        "print('Input : {} Ouput : {}'.format(input_size, out_size))\n",
        "\n",
        "embed_size = 256\n",
        "hidden_size = 512\n",
        "num_layers = 1\n",
        "num_iteration = 100000\n",
        "\n",
        "encoder = Encoder(input_size, hidden_size, embed_size, num_layers)\n",
        "decoder = Decoder(out_size, hidden_size, embed_size, num_layers)\n",
        "\n",
        "model = Seq2Seq(encoder, decoder)\n",
        "print(encoder)\n",
        "print(\"=\" * 50)\n",
        "print(decoder)\n",
        "\n",
        "model = trainModel(model, source, target, pairs, num_iteration)\n",
        "evaluateRandomly(model, source, target, pairs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsBS9-JardqA",
        "outputId": "8acb64f3-498b-45d2-a692-00f2328ff550"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 8081 sentence pairs\n",
            "Random sentence ['nobody cares about this except you.', 'khong ai quan tam en ieu o tru cau ra.']\n",
            "Input : 5353 Ouput : 2046\n",
            "Encoder(\n",
            "  (embedding): Embedding(5353, 256)\n",
            "  (gru): GRU(256, 512)\n",
            ")\n",
            "==================================================\n",
            "Decoder(\n",
            "  (embedding): Embedding(2046, 256)\n",
            "  (gru): GRU(256, 512)\n",
            "  (out): Linear(in_features=512, out_features=2046, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n",
            "5000 3.8192\n",
            "10000 3.6202\n",
            "15000 3.6330\n",
            "20000 3.5875\n",
            "25000 3.5776\n",
            "30000 3.5886\n",
            "35000 3.5473\n",
            "40000 3.5916\n",
            "45000 3.5313\n",
            "50000 3.6015\n",
            "55000 3.5529\n",
            "60000 3.5933\n",
            "65000 3.5791\n",
            "70000 3.5677\n",
            "75000 3.5252\n",
            "80000 3.5323\n",
            "85000 3.5360\n",
            "90000 3.5454\n",
            "95000 3.5426\n",
            "100000 3.5497\n",
            "source tom wanted me to tell you to buy a couple of loaves of bread on your way home.\n",
            "target tom muon toi dan ban mua mot vai o banh mi tren uong ve nha.\n",
            "Predicted toi co co co <EOS>\n",
            "source i really need to hit somebody.\n",
            "target toi muon am ai o cho thoa thich.\n",
            "Predicted toi co co co <EOS>\n",
            "source tom dusted himself off.\n",
            "target tom ru sach bui tren nguoi.\n",
            "Predicted toi co co co <EOS>\n",
            "source who do you think she lives with?\n",
            "target tui bay nghi no o voi ai?\n",
            "Predicted toi co co co <EOS>\n",
            "source their eyes met.\n",
            "target anh mat ho cham nhau.\n",
            "Predicted toi co co co <EOS>\n",
            "source we get together once a year.\n",
            "target chung toi gap nhau moi nam mot lan.\n",
            "Predicted toi co co co <EOS>\n",
            "source he always puts himself first.\n",
            "target anh ay luon at loi ich cua minh len tren het.\n",
            "Predicted toi co co co <EOS>\n",
            "source tom is always the first one to complain.\n",
            "target tom luon la nguoi than phien au tien.\n",
            "Predicted toi co co co <EOS>\n",
            "source listen to each other.\n",
            "target hay lang nghe lan nhau.\n",
            "Predicted toi co co co <EOS>\n",
            "source tom was late because of the heavy snow.\n",
            "target tom a en muon vi tuyet roi day.\n",
            "Predicted toi co co co <EOS>\n"
          ]
        }
      ]
    }
  ]
}