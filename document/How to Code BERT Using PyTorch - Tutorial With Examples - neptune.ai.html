<!DOCTYPE html>
<!-- saved from url=(0063)https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial -->
<html lang="en-US" class="jetpack-lazy-images-js-enabled"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">
    <title>How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai</title>
    <link rel="preconnect" href="https://fonts.gstatic.com/">
    <link href="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/css2" rel="stylesheet">
    <meta name="robots" content="index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1">

	<!-- This site is optimized with the Yoast SEO plugin v19.9 - https://yoast.com/wordpress/plugins/seo/ -->
	<link rel="canonical" href="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial">
	<meta property="og:locale" content="en_US">
	<meta property="og:type" content="article">
	<meta property="og:title" content="How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai">
	<meta property="og:description" content="If you are an NLP enthusiast then you might have heard about BERT. In this article, we are going to explore BERT: what it is? and how it works?, and learn how to code it using PyTorch. In 2018, Google published a paper titled “Pre-training of deep bidirectional transformers for language understanding”. In this paper, […]">
	<meta property="og:url" content="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial">
	<meta property="og:site_name" content="neptune.ai">
	<meta property="article:publisher" content="https://www.facebook.com/neptuneML/">
	<meta property="article:published_time" content="2021-05-20T08:02:00+00:00">
	<meta property="article:modified_time" content="2022-07-21T15:14:12+00:00">
	<meta property="og:image" content="https://neptune.ai/wp-content/uploads/How-to-code-BERT.jpg">
	<meta property="og:image:width" content="1920">
	<meta property="og:image:height" content="1377">
	<meta property="og:image:type" content="image/jpeg">
	<meta name="author" content="Nilesh Barla">
	<meta name="twitter:card" content="summary_large_image">
	<meta name="twitter:creator" content="@neptuneml">
	<meta name="twitter:site" content="@neptuneml">
	<meta name="twitter:label1" content="Written by">
	<meta name="twitter:data1" content="Nilesh Barla">
	<meta name="twitter:label2" content="Est. reading time">
	<meta name="twitter:data2" content="24 minutes">
	<script type="text/javascript" async="" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/wqilukic"></script><script type="text/javascript" async="" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/heap-3102000718.js"></script><script type="text/javascript" async="" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/recaptcha__en.js" crossorigin="anonymous" integrity="sha384-ALtiHf0DOZRoBKnCKTk/SlH3koiTb5V8tXxijiVbKfgMusXfsD91H2zPixteloxy"></script><script src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/123046552428646" async=""></script><script async="" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/fbevents.js"></script><script type="text/javascript" async="" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/uwt.js"></script><script type="text/javascript" async="" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/pixel.js"></script><script type="text/javascript" async="" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/analytics.js"></script><script async="" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/gtm.js"></script><script type="application/ld+json" class="yoast-schema-graph">{"@context":"https://schema.org","@graph":[{"@type":"WebPage","@id":"https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial","url":"https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial","name":"How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai","isPartOf":{"@id":"https://neptune.ai/#website"},"primaryImageOfPage":{"@id":"https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial#primaryimage"},"image":{"@id":"https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial#primaryimage"},"thumbnailUrl":"https://i0.wp.com/neptune.ai/wp-content/uploads/How-to-code-BERT.jpg?fit=1920%2C1377&ssl=1","datePublished":"2021-05-20T08:02:00+00:00","dateModified":"2022-07-21T15:14:12+00:00","author":{"@id":"https://neptune.ai/#/schema/person/24ba60ae0c3052a9cb3e4ac0f1a25859"},"breadcrumb":{"@id":"https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial#breadcrumb"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial"]}]},{"@type":"ImageObject","inLanguage":"en-US","@id":"https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial#primaryimage","url":"https://i0.wp.com/neptune.ai/wp-content/uploads/How-to-code-BERT.jpg?fit=1920%2C1377&ssl=1","contentUrl":"https://i0.wp.com/neptune.ai/wp-content/uploads/How-to-code-BERT.jpg?fit=1920%2C1377&ssl=1","width":1920,"height":1377,"caption":"How to code BERT"},{"@type":"BreadcrumbList","@id":"https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial#breadcrumb","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://neptune.ai/blog"},{"@type":"ListItem","position":2,"name":"Natural Language Processing","item":"https://neptune.ai/blog/category/natural-language-processing"},{"@type":"ListItem","position":3,"name":"How to Code BERT Using PyTorch &#8211; Tutorial With Examples"}]},{"@type":"WebSite","@id":"https://neptune.ai/#website","url":"https://neptune.ai/","name":"neptune.ai","description":"Metadata store for MLOps, built for teams that run a lot of experiments.","potentialAction":[{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://neptune.ai/?s={search_term_string}"},"query-input":"required name=search_term_string"}],"inLanguage":"en-US"},{"@type":"Person","@id":"https://neptune.ai/#/schema/person/24ba60ae0c3052a9cb3e4ac0f1a25859","name":"Nilesh Barla","image":{"@type":"ImageObject","inLanguage":"en-US","@id":"https://neptune.ai/#/schema/person/image/","url":"https://secure.gravatar.com/avatar/?s=96&d=blank&r=g","contentUrl":"https://secure.gravatar.com/avatar/?s=96&d=blank&r=g","caption":"Nilesh Barla"},"url":"https://neptune.ai/blog/author/nilesh-barla"}]}</script>
	<!-- / Yoast SEO plugin. -->


<link rel="dns-prefetch" href="https://secure.gravatar.com/">
<link rel="dns-prefetch" href="https://code.jquery.com/">
<link rel="dns-prefetch" href="https://ajax.googleapis.com/">
<link rel="dns-prefetch" href="https://cdnjs.cloudflare.com/">
<link rel="dns-prefetch" href="https://stackpath.bootstrapcdn.com/">
<link rel="dns-prefetch" href="https://www.google.com/">
<link rel="dns-prefetch" href="https://s.w.org/">
<link rel="dns-prefetch" href="https://widgets.wp.com/">
<link rel="dns-prefetch" href="https://i0.wp.com/">
<link rel="dns-prefetch" href="https://c0.wp.com/">
<link rel="dns-prefetch" href="https://v0.wordpress.com/">
<link rel="alternate" type="application/rss+xml" title="neptune.ai » How to Code BERT Using PyTorch – Tutorial With Examples Comments Feed" href="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial/feed">
<script type="text/javascript">
window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/14.0.0\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/14.0.0\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/neptune.ai\/wp-includes\/js\/wp-emoji-release.min.js?ver=6.0.3"}};
/*! This file is auto-generated */
!function(e,a,t){var n,r,o,i=a.createElement("canvas"),p=i.getContext&&i.getContext("2d");function s(e,t){var a=String.fromCharCode,e=(p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,e),0,0),i.toDataURL());return p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,t),0,0),e===i.toDataURL()}function c(e){var t=a.createElement("script");t.src=e,t.defer=t.type="text/javascript",a.getElementsByTagName("head")[0].appendChild(t)}for(o=Array("flag","emoji"),t.supports={everything:!0,everythingExceptFlag:!0},r=0;r<o.length;r++)t.supports[o[r]]=function(e){if(!p||!p.fillText)return!1;switch(p.textBaseline="top",p.font="600 32px Arial",e){case"flag":return s([127987,65039,8205,9895,65039],[127987,65039,8203,9895,65039])?!1:!s([55356,56826,55356,56819],[55356,56826,8203,55356,56819])&&!s([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]);case"emoji":return!s([129777,127995,8205,129778,127999],[129777,127995,8203,129778,127999])}return!1}(o[r]),t.supports.everything=t.supports.everything&&t.supports[o[r]],"flag"!==o[r]&&(t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&t.supports[o[r]]);t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&!t.supports.flag,t.DOMReady=!1,t.readyCallback=function(){t.DOMReady=!0},t.supports.everything||(n=function(){t.readyCallback()},a.addEventListener?(a.addEventListener("DOMContentLoaded",n,!1),e.addEventListener("load",n,!1)):(e.attachEvent("onload",n),a.attachEvent("onreadystatechange",function(){"complete"===a.readyState&&t.readyCallback()})),(e=t.source||{}).concatemoji?c(e.concatemoji):e.wpemoji&&e.twemoji&&(c(e.twemoji),c(e.wpemoji)))}(window,document,window._wpemojiSettings);
</script><script src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/wp-emoji-release.min.js" type="text/javascript" defer=""></script>
<style type="text/css">
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 0.07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
	<link rel="stylesheet" id="wp-block-library-css" href="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/style.min.css" type="text/css" media="all">
<style id="wp-block-library-inline-css" type="text/css">
.has-text-align-justify{text-align:justify;}
</style>
<link rel="stylesheet" id="mediaelement-css" href="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/mediaelementplayer-legacy.min.css" type="text/css" media="all">
<link rel="stylesheet" id="wp-mediaelement-css" href="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/wp-mediaelement.min.css" type="text/css" media="all">
<link rel="stylesheet" id="wp-bootstrap-blocks-styles-css" href="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/style-index.css" type="text/css" media="all">
<style id="global-styles-inline-css" type="text/css">
body{--wp--preset--color--black: #000000;--wp--preset--color--cyan-bluish-gray: #abb8c3;--wp--preset--color--white: #ffffff;--wp--preset--color--pale-pink: #f78da7;--wp--preset--color--vivid-red: #cf2e2e;--wp--preset--color--luminous-vivid-orange: #ff6900;--wp--preset--color--luminous-vivid-amber: #fcb900;--wp--preset--color--light-green-cyan: #7bdcb5;--wp--preset--color--vivid-green-cyan: #00d084;--wp--preset--color--pale-cyan-blue: #8ed1fc;--wp--preset--color--vivid-cyan-blue: #0693e3;--wp--preset--color--vivid-purple: #9b51e0;--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple: linear-gradient(135deg,rgba(6,147,227,1) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan: linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange: linear-gradient(135deg,rgba(252,185,0,1) 0%,rgba(255,105,0,1) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red: linear-gradient(135deg,rgba(255,105,0,1) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray: linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum: linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple: linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux: linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk: linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean: linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass: linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight: linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--duotone--dark-grayscale: url('#wp-duotone-dark-grayscale');--wp--preset--duotone--grayscale: url('#wp-duotone-grayscale');--wp--preset--duotone--purple-yellow: url('#wp-duotone-purple-yellow');--wp--preset--duotone--blue-red: url('#wp-duotone-blue-red');--wp--preset--duotone--midnight: url('#wp-duotone-midnight');--wp--preset--duotone--magenta-yellow: url('#wp-duotone-magenta-yellow');--wp--preset--duotone--purple-green: url('#wp-duotone-purple-green');--wp--preset--duotone--blue-orange: url('#wp-duotone-blue-orange');--wp--preset--font-size--small: 14px;--wp--preset--font-size--medium: 18px;--wp--preset--font-size--large: 36px;--wp--preset--font-size--x-large: 42px;--wp--preset--font-size--normal: 16px;--wp--preset--font-size--big: 20px;--wp--preset--font-size--huge: 22px;}.has-black-color{color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-color{color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-color{color: var(--wp--preset--color--white) !important;}.has-pale-pink-color{color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-color{color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-color{color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-color{color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-color{color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-color{color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-color{color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-color{color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-color{color: var(--wp--preset--color--vivid-purple) !important;}.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-background-color{background-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.has-pale-pink-background-color{background-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-background-color{background-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-background-color{background-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-background-color{background-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-background-color{background-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-background-color{background-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-background-color{background-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-background-color{background-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-background-color{background-color: var(--wp--preset--color--vivid-purple) !important;}.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-border-color{border-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}.has-pale-pink-border-color{border-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-border-color{border-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-border-color{border-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-border-color{border-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-border-color{border-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-border-color{border-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-border-color{border-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-border-color{border-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-border-color{border-color: var(--wp--preset--color--vivid-purple) !important;}.has-vivid-cyan-blue-to-vivid-purple-gradient-background{background: var(--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple) !important;}.has-light-green-cyan-to-vivid-green-cyan-gradient-background{background: var(--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan) !important;}.has-luminous-vivid-amber-to-luminous-vivid-orange-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange) !important;}.has-luminous-vivid-orange-to-vivid-red-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-orange-to-vivid-red) !important;}.has-very-light-gray-to-cyan-bluish-gray-gradient-background{background: var(--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray) !important;}.has-cool-to-warm-spectrum-gradient-background{background: var(--wp--preset--gradient--cool-to-warm-spectrum) !important;}.has-blush-light-purple-gradient-background{background: var(--wp--preset--gradient--blush-light-purple) !important;}.has-blush-bordeaux-gradient-background{background: var(--wp--preset--gradient--blush-bordeaux) !important;}.has-luminous-dusk-gradient-background{background: var(--wp--preset--gradient--luminous-dusk) !important;}.has-pale-ocean-gradient-background{background: var(--wp--preset--gradient--pale-ocean) !important;}.has-electric-grass-gradient-background{background: var(--wp--preset--gradient--electric-grass) !important;}.has-midnight-gradient-background{background: var(--wp--preset--gradient--midnight) !important;}.has-small-font-size{font-size: var(--wp--preset--font-size--small) !important;}.has-medium-font-size{font-size: var(--wp--preset--font-size--medium) !important;}.has-large-font-size{font-size: var(--wp--preset--font-size--large) !important;}.has-x-large-font-size{font-size: var(--wp--preset--font-size--x-large) !important;}
</style>
<link rel="stylesheet" id="contact-form-7-css" href="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/styles.css" type="text/css" media="all">
<link rel="stylesheet" id="cookie-law-info-css" href="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/cookie-law-info-public.css" type="text/css" media="all">
<link rel="stylesheet" id="cookie-law-info-gdpr-css" href="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/cookie-law-info-gdpr.css" type="text/css" media="all">
<link rel="stylesheet" id="lbwps-styles-photoswipe5-main-css" href="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/main.css" type="text/css" media="all">
<link rel="stylesheet" id="bootstrap-css" href="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/bootstrap.min.css" type="text/css" media="all">
<link rel="stylesheet" id="style-css" href="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/style.css" type="text/css" media="all">
<link rel="stylesheet" id="jetpack_css-css" href="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/jetpack.css" type="text/css" media="all">
<script type="text/javascript" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/jquery-3.5.1.min.js" id="jquery-js"></script>
<script type="text/javascript" id="cookie-law-info-js-extra">
/* <![CDATA[ */
var Cli_Data = {"nn_cookie_ids":[],"cookielist":[],"non_necessary_cookies":[],"ccpaEnabled":"","ccpaRegionBased":"","ccpaBarEnabled":"","strictlyEnabled":["necessary","obligatoire"],"ccpaType":"gdpr","js_blocking":"1","custom_integration":"","triggerDomRefresh":"","secure_cookies":""};
var cli_cookiebar_settings = {"animate_speed_hide":"500","animate_speed_show":"500","background":"#FFF","border":"#b1a6a6c2","border_on":"","button_1_button_colour":"#00b978","button_1_button_hover":"#009460","button_1_link_colour":"#fff","button_1_as_button":"1","button_1_new_win":"","button_2_button_colour":"#333","button_2_button_hover":"#292929","button_2_link_colour":"#444","button_2_as_button":"","button_2_hidebar":"","button_3_button_colour":"#3566bb","button_3_button_hover":"#2a5296","button_3_link_colour":"#fff","button_3_as_button":"1","button_3_new_win":"","button_4_button_colour":"#000","button_4_button_hover":"#000000","button_4_link_colour":"#333333","button_4_as_button":"","button_7_button_colour":"#61a229","button_7_button_hover":"#4e8221","button_7_link_colour":"#fff","button_7_as_button":"1","button_7_new_win":"","font_family":"inherit","header_fix":"","notify_animate_hide":"1","notify_animate_show":"","notify_div_id":"#cookie-law-info-bar","notify_position_horizontal":"right","notify_position_vertical":"bottom","scroll_close":"","scroll_close_reload":"","accept_close_reload":"","reject_close_reload":"","showagain_tab":"","showagain_background":"#fff","showagain_border":"#000","showagain_div_id":"#cookie-law-info-again","showagain_x_position":"100px","text":"#ccd5ff","show_once_yn":"","show_once":"10000","logging_on":"","as_popup":"","popup_overlay":"1","bar_heading_text":"","cookie_bar_as":"banner","popup_showagain_position":"bottom-right","widget_position":"left"};
var log_object = {"ajax_url":"https:\/\/neptune.ai\/wp-admin\/admin-ajax.php"};
/* ]]> */
</script>
<script type="text/javascript" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/cookie-law-info-public.js" id="cookie-law-info-js"></script>
<link rel="https://api.w.org/" href="https://neptune.ai/wp-json/"><link rel="alternate" type="application/json" href="https://neptune.ai/wp-json/wp/v2/posts/45909"><link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://neptune.ai/xmlrpc.php?rsd">
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="https://neptune.ai/wp-includes/wlwmanifest.xml"> 
<link rel="shortlink" href="https://wp.me/paIqge-bWt">
<link rel="alternate" type="application/json+oembed" href="https://neptune.ai/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fneptune.ai%2Fblog%2Fhow-to-code-bert-using-pytorch-tutorial">
<link rel="alternate" type="text/xml+oembed" href="https://neptune.ai/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fneptune.ai%2Fblog%2Fhow-to-code-bert-using-pytorch-tutorial&amp;format=xml">
	<style>img#wpstats{display:none}</style>
		<style type="text/css"></style>		<style type="text/css">
			.recentcomments a {
				display: inline !important;
				padding: 0 !important;
				margin: 0 !important;
			}

			table.recentcommentsavatartop img.avatar, table.recentcommentsavatarend img.avatar {
				border: 0px;
				margin: 0;
			}

			table.recentcommentsavatartop a, table.recentcommentsavatarend a {
				border: 0px !important;
				background-color: transparent !important;
			}

			td.recentcommentsavatarend, td.recentcommentsavatartop {
				padding: 0px 0px 1px 0px;
				margin: 0px;
			}

			td.recentcommentstextend {
				border: none !important;
				padding: 0px 0px 2px 10px;
			}

			.rtl td.recentcommentstextend {
				padding: 0px 10px 2px 0px;
			}

			td.recentcommentstexttop {
				border: none;
				padding: 0px 0px 0px 10px;
			}

			.rtl td.recentcommentstexttop {
				padding: 0px 10px 0px 0px;
			}
		</style>
		<link rel="amphtml" href="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial/amp">			<style type="text/css">
				/* If html does not have either class, do not show lazy loaded images. */
				html:not( .jetpack-lazy-images-js-enabled ):not( .js ) .jetpack-lazy-image {
					display: none;
				}
			</style>
			<script>
				document.documentElement.classList.add(
					'jetpack-lazy-images-js-enabled'
				);
			</script>
		<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-MZNL966');</script>
<!-- End Google Tag Manager -->
<script src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/optimize.js"></script><link rel="icon" href="https://i0.wp.com/neptune.ai/wp-content/uploads/2019/03/cropped-Artboard-12.png?fit=32%2C32&amp;ssl=1" sizes="32x32">
<link rel="icon" href="https://i0.wp.com/neptune.ai/wp-content/uploads/2019/03/cropped-Artboard-12.png?fit=192%2C192&amp;ssl=1" sizes="192x192">
<link rel="apple-touch-icon" href="https://i0.wp.com/neptune.ai/wp-content/uploads/2019/03/cropped-Artboard-12.png?fit=180%2C180&amp;ssl=1">
<meta name="msapplication-TileImage" content="https://i0.wp.com/neptune.ai/wp-content/uploads/2019/03/cropped-Artboard-12.png?fit=270%2C270&amp;ssl=1">
<style type="text/css" id="wp-custom-css">.section.jobs.article{
	max-width: 900px;
}
/*testimonials-grid-block*/
.testimonials-grid-header__logo {
   
    height: 90px!important;
	 width: 90px!important;
}
/*customers-new-footer*/
.page-id-65330 footer{
	margin-top:0;
}</style><meta http-equiv="origin-trial" content="A751Xsk4ZW3DVQ8WZng2Dk5s3YzAyqncTzgv+VaE6wavgTY0QHkDvUTET1o7HanhuJO8lgv1Vvc88Ij78W1FIAAAAAB7eyJvcmlnaW4iOiJodHRwczovL3d3dy5nb29nbGV0YWdtYW5hZ2VyLmNvbTo0NDMiLCJmZWF0dXJlIjoiUHJpdmFjeVNhbmRib3hBZHNBUElzIiwiZXhwaXJ5IjoxNjgwNjUyNzk5LCJpc1RoaXJkUGFydHkiOnRydWV9"><script type="text/javascript" async="" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/f.txt"></script><script async="" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/hotjar-569747.js"></script><script async="" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/modules.cb462d06d2679bf31ed1.js" charset="utf-8"></script><style type="text/css">iframe#_hjRemoteVarsFrame {display: none !important; width: 1px !important; height: 1px !important; opacity: 0 !important; pointer-events: none !important;}</style></head>

<body class="post-template-default single single-post postid-45909 single-format-standard sidebar-style-first footer-out-newsletter" data-hide-topbar="" style="padding-top: 129px;">
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;"><defs><filter id="wp-duotone-dark-grayscale"><fecolormatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 "></fecolormatrix><fecomponenttransfer color-interpolation-filters="sRGB"><fefuncr type="table" tableValues="0 0.49803921568627"></fefuncr><fefuncg type="table" tableValues="0 0.49803921568627"></fefuncg><fefuncb type="table" tableValues="0 0.49803921568627"></fefuncb><fefunca type="table" tableValues="1 1"></fefunca></fecomponenttransfer><fecomposite in2="SourceGraphic" operator="in"></fecomposite></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;"><defs><filter id="wp-duotone-grayscale"><fecolormatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 "></fecolormatrix><fecomponenttransfer color-interpolation-filters="sRGB"><fefuncr type="table" tableValues="0 1"></fefuncr><fefuncg type="table" tableValues="0 1"></fefuncg><fefuncb type="table" tableValues="0 1"></fefuncb><fefunca type="table" tableValues="1 1"></fefunca></fecomponenttransfer><fecomposite in2="SourceGraphic" operator="in"></fecomposite></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;"><defs><filter id="wp-duotone-purple-yellow"><fecolormatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 "></fecolormatrix><fecomponenttransfer color-interpolation-filters="sRGB"><fefuncr type="table" tableValues="0.54901960784314 0.98823529411765"></fefuncr><fefuncg type="table" tableValues="0 1"></fefuncg><fefuncb type="table" tableValues="0.71764705882353 0.25490196078431"></fefuncb><fefunca type="table" tableValues="1 1"></fefunca></fecomponenttransfer><fecomposite in2="SourceGraphic" operator="in"></fecomposite></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;"><defs><filter id="wp-duotone-blue-red"><fecolormatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 "></fecolormatrix><fecomponenttransfer color-interpolation-filters="sRGB"><fefuncr type="table" tableValues="0 1"></fefuncr><fefuncg type="table" tableValues="0 0.27843137254902"></fefuncg><fefuncb type="table" tableValues="0.5921568627451 0.27843137254902"></fefuncb><fefunca type="table" tableValues="1 1"></fefunca></fecomponenttransfer><fecomposite in2="SourceGraphic" operator="in"></fecomposite></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;"><defs><filter id="wp-duotone-midnight"><fecolormatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 "></fecolormatrix><fecomponenttransfer color-interpolation-filters="sRGB"><fefuncr type="table" tableValues="0 0"></fefuncr><fefuncg type="table" tableValues="0 0.64705882352941"></fefuncg><fefuncb type="table" tableValues="0 1"></fefuncb><fefunca type="table" tableValues="1 1"></fefunca></fecomponenttransfer><fecomposite in2="SourceGraphic" operator="in"></fecomposite></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;"><defs><filter id="wp-duotone-magenta-yellow"><fecolormatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 "></fecolormatrix><fecomponenttransfer color-interpolation-filters="sRGB"><fefuncr type="table" tableValues="0.78039215686275 1"></fefuncr><fefuncg type="table" tableValues="0 0.94901960784314"></fefuncg><fefuncb type="table" tableValues="0.35294117647059 0.47058823529412"></fefuncb><fefunca type="table" tableValues="1 1"></fefunca></fecomponenttransfer><fecomposite in2="SourceGraphic" operator="in"></fecomposite></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;"><defs><filter id="wp-duotone-purple-green"><fecolormatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 "></fecolormatrix><fecomponenttransfer color-interpolation-filters="sRGB"><fefuncr type="table" tableValues="0.65098039215686 0.40392156862745"></fefuncr><fefuncg type="table" tableValues="0 1"></fefuncg><fefuncb type="table" tableValues="0.44705882352941 0.4"></fefuncb><fefunca type="table" tableValues="1 1"></fefunca></fecomponenttransfer><fecomposite in2="SourceGraphic" operator="in"></fecomposite></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;"><defs><filter id="wp-duotone-blue-orange"><fecolormatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 "></fecolormatrix><fecomponenttransfer color-interpolation-filters="sRGB"><fefuncr type="table" tableValues="0.098039215686275 1"></fefuncr><fefuncg type="table" tableValues="0 0.66274509803922"></fefuncg><fefuncb type="table" tableValues="0.84705882352941 0.41960784313725"></fefuncb><fefunca type="table" tableValues="1 1"></fefunca></fecomponenttransfer><fecomposite in2="SourceGraphic" operator="in"></fecomposite></filter></defs></svg>    <div class="neptune-topbar">
        <div class="topbar-content">
            <div class="content"><p>We Raised $8M Series A to Continue Building Experiment Tracking and Model Registry That “Just Works”</p>
</div>
            <a href="https://neptune.ai/blog/series-a-announcement" target="_blank">Read more</a>        </div>
        <a href="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial#" class="remove-topbar">
            <img src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/times-icon.svg">
        </a>
    </div>
<header class="header header-new-blog has-topbar" style="margin-top: 60px;">
    <div class="container">
        <div class="logo-container">
            <a href="https://neptune.ai/">
                <img src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/logo-short.svg">            </a>
            <a href="https://neptune.ai/blog/" class="blog-link">
                blog
            </a>
        </div>
        <div class="right-container">
            <div class="search-container">
                


<form action="https://neptune.ai/blog/" method="get" class="header__search header__search--tablet">
  <input type="text" id="autocomplate" name="s" value="" placeholder="Search all articles" class="header__search-input">
    <input type="hidden" value="post" name="post_type">
  <input type="submit" class="header__search-submit">
  <div class="ajax-results"></div>
</form>            </div>
            <div class="newsletter-container">
                <a href="https://neptune.us19.list-manage.com/subscribe?u=8da2bdd288186da3ffeec5626&amp;id=59d3dc2c24" target="_blank">Get Newsletter</a>            </div>
            <a href="https://go.mlops.community/slack" class="slack-url">
                <img src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/slack-logo.svg">            </a>
        </div>
    </div>
</header>
<div class="blog-category-slider">
    <div class="container">
        <div class="category-path">
            <a href="https://neptune.ai/blog/">Blog</a>
        </div>
        <div class="categories-list">
                        <div class="single-category-element current-cat">
                <a href="https://neptune.ai/blog/category/natural-language-processing">
                    Natural Language Processing                </a>
            </div>
                                        <div class="single-category-element">
                    <a href="https://neptune.ai/blog/category/machine-learning-model-development">
                        ML Model Development                    </a>
                </div>
                            <div class="single-category-element">
                    <a href="https://neptune.ai/blog/category/mlops">
                        MLOps                    </a>
                </div>
                            <div class="single-category-element">
                    <a href="https://neptune.ai/blog/category/machine-learning-tools">
                        Machine Learning Tools                    </a>
                </div>
                            <div class="single-category-element">
                    <a href="https://neptune.ai/blog/category/computer-vision">
                        Computer Vision                    </a>
                </div>
                            <div class="single-category-element">
                    <a href="https://neptune.ai/blog/category/reinforcement-learning">
                        Reinforcement Learning                    </a>
                </div>
                            <div class="single-category-element">
                    <a href="https://neptune.ai/blog/category/tabular-data">
                        Tabular Data                    </a>
                </div>
                            <div class="single-category-element">
                    <a href="https://neptune.ai/blog/category/time-series-forecasting">
                        Time Series                    </a>
                </div>
                    </div>
        <a href="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial#" class="next-cat">
            <img src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/blog-next-cat.svg">        </a>
    </div>
</div>
<main class="main blog">
  <section class="section blog__section singlePost container">

    <div class="article__row row">
              <aside class="col-12 sidebar col-lg-3" style="z-index: 1; margin-top: 0px;">        <div class="before-sidebar-newsletter" style="width: 410.3px; display: block;"></div>
<a href="https://app.neptune.ai/showcase/project-text-classification/e/TXTCLF-237/dashboard/Overview-97290085-2953-4fff-a962-4e8ed140f07e" target="_blank" class="sidebar-newsletter sidebar-newsletter--sticky" style="width: 347px; opacity: 1; display: flex;">
    <div class="sidebar-newsletter__content"><p><strong>Working on an NLP project?</strong></p>
<p>You may be spending too much time documenting it. Adding a metadata store to your workflow can change this.</p>
</div>
            <span class="button green-filled sidebar-newsletter__button">
            See example dashboard        </span>
    
</a>
</aside>
      
      <article class="col-12 col-lg-9 article">
        <header class="article__header col-lg-10">  <h1 class="article__title">How to Code BERT Using PyTorch – Tutorial With Examples</h1>
  <ul class="article__info">
    <li class="article__info-single article__info--read-single">
      <span class="article__info-time">16</span>
      <span class="article__info-mins">mins</span>
      <span class="article__info-read">read</span>
    </li>
    <li class="article__info-single author-info">
        Author Nilesh Barla    </li>
          <li class="article__info-single">Updated July 21st, 2022</li>
      </ul>
</header>
        <div class="article__content col-lg-10">
<p>If you are an NLP enthusiast then you might have heard about BERT. In this article, we are going to explore BERT: what it is? and how it works?, and learn how to code it using PyTorch.</p>



<p>In 2018, Google published a paper titled “<a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank" rel="noreferrer noopener nofollow">Pre-training of deep bidirectional transformers for language understanding</a>”. In this paper, they introduced a language model called <strong>BERT (Bidirectional Encoder Representation with Transformers)</strong> that achieved state-of-the-art performance in tasks like <em>Question-Answering</em>, <em>Natural Language Inference, Classification, and General language understanding evaluation or (GLUE)</em>.</p>



<p>BERT release was followed after the release of three architectures that also achieved state-of-the-art performances. These models were:&nbsp;</p>


<div class="custom-point-list">
<ul><li>ULM-Fit (January)</li><li>ELMo (February),&nbsp;</li><li>OpenAI GPT (June)&nbsp;</li><li>BERT (October).&nbsp;</li></ul>
</div>


<p>The OpenAI GPT and BERT use the <a href="https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf" target="_blank" rel="noreferrer noopener nofollow"><strong>Transformer</strong></a> architecture that does not use recurrent neural networks; this enabled the architecture to take into account long-term dependencies through the <strong>self-attention mechanism </strong>that inherently changed the way we model sequential data. It introduced an <strong>encoder-decoder</strong> architecture which was seen in computer vision applications such as image generation through variational autoencoder encoder.&nbsp;</p>



<p>So how is BERT different from all the models that were released in 2018?&nbsp;</p>



<p>Well, to answer that question we need to understand what BERT is and how it works.&nbsp;</p>



<p>So, let’s begin.&nbsp;</p>



<h2>What is BERT?</h2>



<p>BERT stands for “Bidirectional Encoder Representation with Transformers”. To put it in simple words BERT extracts patterns or representations from the data or word embeddings by passing it through an encoder. The encoder itself is a transformer architecture that is stacked together. It is a bidirectional transformer which means that during training it considers the context from both left and right of the vocabulary to extract patterns or representations.&nbsp;</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img data-attachment-id="45968" data-permalink="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial/attachment/bert-encoder" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-encoder.png?fit=428%2C550&amp;ssl=1" data-orig-size="428,550" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BERT-encoder" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-encoder.png?fit=233%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-encoder.png?fit=428%2C550&amp;ssl=1" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/BERT-encoder.png" alt="BERT encoder" class="wp-image-45968 jetpack-lazy-image jetpack-lazy-image--handled" width="321" height="413" data-recalc-dims="1" data-lazy-loaded="1" loading="eager"><noscript><img data-lazy-fallback="1" data-attachment-id="45968" data-permalink="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial/attachment/bert-encoder" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-encoder.png?fit=428%2C550&amp;ssl=1" data-orig-size="428,550" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BERT-encoder" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-encoder.png?fit=233%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-encoder.png?fit=428%2C550&amp;ssl=1" src="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-encoder.png?resize=321%2C413&#038;ssl=1" alt="BERT encoder" class="wp-image-45968" width="321" height="413" data-recalc-dims="1"  /></noscript><figcaption><a href="http://jalammar.github.io/illustrated-bert/" target="_blank" rel="noreferrer noopener nofollow"><em>Source</em></a></figcaption></figure></div>



<p>BERT uses two training paradigms: <strong>Pre-training</strong> and <strong>Fine-tuning</strong>.&nbsp;</p>



<p>During <strong>pre-training,</strong> the model is trained on a large dataset to extract patterns. This is generally an <strong>unsupervised learning</strong> task where the model is trained on an unlabelled dataset like the data from a big corpus like Wikipedia.&nbsp;&nbsp;</p>



<p>During<strong> fine-tuning</strong> the model is trained for downstream tasks like Classification, Text-Generation, Language Translation, Question-Answering, and so forth. Essentially, you can download a pre-trained model and then Transfer-learn the model on your data.&nbsp;</p>



<div id="blog-cta-intext-block_60a29a39ac11c" class="blog-cta-intext">
  <h3 class="blog-cta-intext__title">Might interest you</h3>
  <div class="blog-cta-intext__content"><p><img draggable="false" role="img" class="emoji" alt="💡" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/1f4a1.svg"> <a href="https://neptune.ai/blog/ai-limits-can-deep-learning-models-like-bert-ever-understand-language" target="_blank" rel="noopener">AI Limits: Can Deep Learning Models Like BERT Ever Understand Language?</a><br>
<img draggable="false" role="img" class="emoji" alt="💡" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/1f4a1.svg"> <a href="https://neptune.ai/blog/bert-and-the-transformer-architecture-reshaping-the-ai-landscape" target="_blank" rel="noopener">10 Things You Need to Know About BERT and the Transformer Architecture That Are Reshaping the AI Landscape</a></p>
</div>
  </div>


<h3>Core components of BERT</h3>



<p>BERT borrows ideas from the previous release SOTA models. Let’s elaborate on that statement.&nbsp;</p>



<h4>The Transformers</h4>



<p>BERT’s main component is the transformer architecture. The transformers are made up of two components: <strong>encoder</strong> and <strong>decoder</strong>. The encoder itself contains two components: the <strong>self-attention layer</strong> and <strong>feed-forward neural network</strong>.&nbsp;</p>



<p>The self-attention layer takes an input and encodes each word into intermediate encoded representations which are then passed through the feed-forward neural network. The feed-forward network passes those representations to the decoder that itself is made up of three components: <strong>self-attention layer, Encoder-Decoder</strong> <strong>Attention,</strong> and <strong>feed-forward neural network</strong>.&nbsp;</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img data-attachment-id="45970" data-permalink="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial/attachment/bert-components" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-components.png?fit=1438%2C536&amp;ssl=1" data-orig-size="1438,536" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BERT-components" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-components.png?fit=300%2C112&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-components.png?fit=1024%2C382&amp;ssl=1" width="1024" height="382" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/BERT-components.png" alt="BERT components" class="wp-image-45970 jetpack-lazy-image jetpack-lazy-image--handled" data-recalc-dims="1" data-lazy-loaded="1" loading="eager"><noscript><img data-lazy-fallback="1" data-attachment-id="45970" data-permalink="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial/attachment/bert-components" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-components.png?fit=1438%2C536&amp;ssl=1" data-orig-size="1438,536" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BERT-components" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-components.png?fit=300%2C112&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-components.png?fit=1024%2C382&amp;ssl=1" width="1024" height="382" src="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-components.png?resize=1024%2C382&#038;ssl=1" alt="BERT components" class="wp-image-45970" data-recalc-dims="1" /></noscript><figcaption><em><a href="http://jalammar.github.io/illustrated-bert/" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p>The benefit of the transformer architecture is that it helps the model to retain infinitely long sequences that were not possible from the traditional RNNs, LSTMs, and GRU. But even from the fact that it can achieve long-term dependencies it still <strong>lacks contextual understanding</strong>.&nbsp;</p>



<p><em>Jay Alammar explains transformers in-depth in his article </em><a href="https://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noreferrer noopener nofollow"><em>The Illustrated Transformer</em></a><em>, worth checking out.&nbsp;</em></p>



<h4>ELMo</h4>



<p>BERT borrows another idea from ELMo which stands for Embeddings from Language Model. ELMo was introduced by <a href="https://arxiv.org/abs/1802.05365" target="_blank" rel="noreferrer noopener nofollow">Peters et. al.</a> in 2017 which dealt with the idea of contextual understanding. The way ELMo works is that it uses <strong>bidirectional</strong> LSTM to make sense of the context. Since it considers words from both directions, it can assign different word embedding to words that are spelled similarly but have different meanings.&nbsp;</p>



<p>For instance, “You kids should <strong>stick</strong> together in the dark” is completely different from “Hand me that <strong>stick</strong>”. Even though the same word is being used in both sentences the meaning is different based on the context.&nbsp;</p>



<p>So, ELMo assigns embeddings by considering the words from both the right and left directions as compared to the models that were developed previously which took into consideration words, only from the left. These models were unidirectional like RNNs, LSTMs et cetera.&nbsp;</p>



<p>This enables ELMo to capture contextual information from the sequences but since ELMo uses LTSM it does not have long-term dependency compared to transformers.</p>



<p>So far we have seen that BERT can access sequences in the document even if it is ‘n’ words behind the current word in the sequence because of the attention mechanism present in transformers, i.e. it can preserve long term dependencies and it can also achieve a contextual understanding of the sentence because of the bidirectional mechanism present in ELMo.&nbsp;</p>



<h4>ULM-FiT</h4>



<p>In 2018 Jeremy Howard and Sebastian Ruder released a paper called <a href="https://arxiv.org/pdf/1801.06146.pdf" target="_blank" rel="noreferrer noopener nofollow">Universal Language Model Fine-tuning or ULM-FiT</a>, where they argued that transfer learning can be used in NLP just like it is used in computer vision.&nbsp;</p>



<p>Previously we were using pre-trained models for word-embeddings that only targeted the first layer of the entire model, i.e. the embedding layers, and the whole model was trained from the scratch, this was time-consuming, and not a lot of success was found in this area. However, Howard and Ruder proposed 3 methods for the classification of text:</p>


<div class="custom-point-list">
<ul><li>The first step includes training the model on a larger dataset so that the model learns representations.&nbsp;</li><li>The second step included fine-tuning the model with a task-specific dataset for classification, during which they introduced two more methods: Discriminative fine-tuning and Slanted triangular learning rates (STLR). The former method tries to fine-tune or optimize the parameters for each during the transfer layer in the network while the latter controls the learning rate in each of the optimization steps.&nbsp;</li><li>The third step was to fine-tune the classifier on the task-specific dataset for classification.&nbsp;</li></ul>
</div>


<div class="wp-block-image"><figure class="aligncenter size-large"><img data-attachment-id="45971" data-permalink="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial/attachment/bert-ulm-fit" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-ULM-FiT.png?fit=1600%2C755&amp;ssl=1" data-orig-size="1600,755" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BERT-ULM-FiT" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-ULM-FiT.png?fit=300%2C142&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-ULM-FiT.png?fit=1024%2C483&amp;ssl=1" width="1024" height="483" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/BERT-ULM-FiT.png" alt="BERT ULM-FiT" class="wp-image-45971 jetpack-lazy-image jetpack-lazy-image--handled" data-recalc-dims="1" data-lazy-loaded="1" loading="eager"><noscript><img data-lazy-fallback="1" data-attachment-id="45971" data-permalink="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial/attachment/bert-ulm-fit" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-ULM-FiT.png?fit=1600%2C755&amp;ssl=1" data-orig-size="1600,755" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BERT-ULM-FiT" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-ULM-FiT.png?fit=300%2C142&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-ULM-FiT.png?fit=1024%2C483&amp;ssl=1" width="1024" height="483" src="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-ULM-FiT.png?resize=1024%2C483&#038;ssl=1" alt="BERT ULM-FiT" class="wp-image-45971" data-recalc-dims="1" /></noscript><figcaption><em><a href="https://arxiv.org/pdf/1801.06146.pdf" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p>With the release of ULM-FiT NLP practitioners can now practice the transfer learning approach in their NLP problems. But the only problem with the ULM-FiT approach to transfer learning was that it included fine-tuning all the layers in the network which was a lot of work.&nbsp;</p>



<h4>OpenAI GPT</h4>



<p>Generative Pre-trained Transformer or GPT was introduced by OpenAI’s team: Radford, Narasimhan, Salimans, and Sutskever. They presented a model that only uses decoders from the transformer instead of encoders in a unidirectional approach. As a result, it outperformed all the previous models in various tasks like:&nbsp;</p>


<div class="custom-point-list">
<ul><li>Classification</li><li>Natural Language Inference</li><li>Semantic similarity</li><li>Question answering&nbsp;</li><li>Multiple Choice.&nbsp;</li></ul>
</div>


<p>Even though the GPT used only the decoder, it could still retain long-term dependencies. Furthermore, it reduced fine-tuning to a minimum compared to what we saw in ULM-FiT.&nbsp;</p>



<p>Below is the table that compares different models based upon pre-training, downstream tasks, and most importantly fine-tuning.&nbsp;</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img data-attachment-id="45972" data-permalink="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial/attachment/language-models-comparison" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Language-models-comparison.png?fit=1364%2C770&amp;ssl=1" data-orig-size="1364,770" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Language-models-comparison" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Language-models-comparison.png?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Language-models-comparison.png?fit=1024%2C578&amp;ssl=1" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/Language-models-comparison.png" alt="Language models comparison" class="wp-image-45972 jetpack-lazy-image jetpack-lazy-image--handled" width="840" height="474" data-recalc-dims="1" data-lazy-loaded="1" loading="eager"><noscript><img data-lazy-fallback="1" data-attachment-id="45972" data-permalink="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial/attachment/language-models-comparison" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Language-models-comparison.png?fit=1364%2C770&amp;ssl=1" data-orig-size="1364,770" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Language-models-comparison" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Language-models-comparison.png?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Language-models-comparison.png?fit=1024%2C578&amp;ssl=1" src="https://i0.wp.com/neptune.ai/wp-content/uploads/Language-models-comparison.png?resize=840%2C474&#038;ssl=1" alt="Language models comparison" class="wp-image-45972" width="840" height="474" data-recalc-dims="1"  /></noscript><figcaption><em><a href="https://medium.com/@gauravghati/comparison-between-bert-gpt-2-and-elmo-9ad140cd1cda" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p>An excerpt from the GPT <a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" target="_blank" rel="noreferrer noopener nofollow">paper</a> reads “<em>This model choice provides us with a more structured memory for handling long-term dependencies in text, compared to alternatives like recurrent networks, resulting in robust transfer performance across diverse tasks. During the transfer, we utilize task-specific input adaptations derived from traversal-style approaches, which process structured text input as a single contiguous sequence of tokens. As we demonstrate in our experiments, these adaptations enable us to fine-tune effectively with minimal changes to the architecture of the pre-trained model.</em>”</p>



<p>Let’s compare all the model with BERT for the tasks they can perform:</p>


<div id="block_61af4ee581c93" class="separator separator-10"></div>


<div class="medium-table">
        <div class="mt-row heading">
            <div class="mt-col" style="width: 20%">
                    </div>
            <div class="mt-col" style="width: 16%">
            Transformer        </div>
            <div class="mt-col" style="width: 16%">
            ELMo        </div>
            <div class="mt-col" style="width: 16%">
            ULM-FiT        </div>
            <div class="mt-col" style="width: 16%">
            OpenAI GPT        </div>
            <div class="mt-col" style="width: 16%">
            BERT        </div>
        </div>
    
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p><strong>Contextual understanding</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Transformer:
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        ELMo:
                    </span>
                                                                <p>Yes<br>
(Weak)</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        ULM-FiT:
                    </span>
                                                                <p>Yes<br>
(Weak)</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        OpenAI GPT:
                    </span>
                                                                <p>Yes<br>
(Moderate)</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        BERT:
                    </span>
                                                                <p>Yes<br>
(Strong)</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p><strong>Long-term dependencies</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Transformer:
                    </span>
                                                                <p>Infinite</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        ELMo:
                    </span>
                                                                <p>Finite</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        ULM-FiT:
                    </span>
                                                                <p>Finite</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        OpenAI GPT:
                    </span>
                                                                <p>Infinite</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        BERT:
                    </span>
                                                                <p>Infinite</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p><strong>Machine translation</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Transformer:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        ELMo:
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        ULM-FiT:
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        OpenAI GPT:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        BERT:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p><strong>Natural language inference</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Transformer:
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        ELMo:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        ULM-FiT:
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        OpenAI GPT:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        BERT:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p><strong>Question answering</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Transformer:
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        ELMo:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        ULM-FiT:
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        OpenAI GPT:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        BERT:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p><strong>Classification or</strong><br>
<strong>sentiment analysis</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Transformer:
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        ELMo:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        ULM-FiT:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        OpenAI GPT:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        BERT:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p><strong>Text generation</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Transformer:
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        ELMo:
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        ULM-FiT:
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        OpenAI GPT:
                    </span>
                                                                <p>Yes<br>
(Poor)</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        BERT:
                    </span>
                                                                <p>No</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p><strong>Fill-Mask</strong></p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        Transformer:
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        ELMo:
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        ULM-FiT:
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        OpenAI GPT:
                    </span>
                                                                <p>No</p>
                                    </div>
                            <div class="mt-col" style="width: 16%">
                                        <span class="column-name">
                        BERT:
                    </span>
                                                                <p>Yes</p>
                                    </div>
                    </div>
    </div>


<div id="block_60a291a8ac116" class="separator separator-20"></div>



<p>You can check <a href="https://huggingface.co/models" target="_blank" rel="noreferrer noopener nofollow">Huggingface models </a>to check the model’s performance on every task.&nbsp;</p>



<h2>Why BERT?</h2>



<p>BERT falls into a <a href="https://neptune.ai/blog/self-supervised-learning" target="_blank" rel="noreferrer noopener">self-supervised</a> model. That means, it can generate inputs and labels from the raw corpus without being explicitly programmed by humans. Remember the data it is trained on is unstructured.&nbsp;</p>



<p>BERT was pre-trained with two specific tasks: Masked Language Model and Next sentence prediction. The former uses masked input like “the man [MASK] to the store” instead of “the man went to the store”. This restricts BERT to see the words next to it which allows it to learn bidirectional representations as much as possible making it much more flexible and reliable for several downstream tasks. The latter predicts whether the two sentences are contextually assigned to each other.&nbsp;</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img data-attachment-id="45973" data-permalink="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial/attachment/bert-masking-1" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-masking-1.png?fit=1398%2C952&amp;ssl=1" data-orig-size="1398,952" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BERT-masking-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-masking-1.png?fit=300%2C204&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-masking-1.png?fit=1024%2C697&amp;ssl=1" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/BERT-masking-1.png" alt="BERT masking" class="wp-image-45973 jetpack-lazy-image jetpack-lazy-image--handled" width="840" height="571" data-recalc-dims="1" data-lazy-loaded="1" loading="eager"><noscript><img data-lazy-fallback="1" data-attachment-id="45973" data-permalink="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial/attachment/bert-masking-1" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-masking-1.png?fit=1398%2C952&amp;ssl=1" data-orig-size="1398,952" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BERT-masking-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-masking-1.png?fit=300%2C204&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-masking-1.png?fit=1024%2C697&amp;ssl=1" src="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-masking-1.png?resize=840%2C571&#038;ssl=1" alt="BERT masking" class="wp-image-45973" width="840" height="571" data-recalc-dims="1"  /></noscript><figcaption><em><a href="http://jalammar.github.io/illustrated-bert/" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p>For instance, if sentence A is “[CLS] the man [MASK] to the store” and sentence B is “penguin [MASK] are flightless birds [SEP]”, then BERT will be able to classify whether both the sentences are continuous or not.&nbsp;</p>



<p>During the training, BERT uses special types of tokens like [CLS], [MASK], [SEP] et cetera, that allow BERT to distinguish when a sentence begins, which word is masked, and when two sentences are separated. I have explained these tokens in tabular format in the <strong>preprocessing</strong> section.&nbsp;</p>



<p><strong>BERT can also be used for feature extraction</strong> because of the properties we discussed previously and feed these extractions to your existing model.&nbsp;</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img data-attachment-id="45974" data-permalink="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial/attachment/bert-feature-extraction" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-feature-extraction.png?fit=1418%2C978&amp;ssl=1" data-orig-size="1418,978" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BERT-feature-extraction" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-feature-extraction.png?fit=300%2C207&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-feature-extraction.png?fit=1024%2C706&amp;ssl=1" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/BERT-feature-extraction-1024x706.png" alt="BERT feature extraction" class="wp-image-45974 jetpack-lazy-image jetpack-lazy-image--handled" width="840" height="579" data-recalc-dims="1" data-lazy-loaded="1" loading="eager"><noscript><img data-lazy-fallback="1" data-attachment-id="45974" data-permalink="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial/attachment/bert-feature-extraction" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-feature-extraction.png?fit=1418%2C978&amp;ssl=1" data-orig-size="1418,978" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BERT-feature-extraction" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-feature-extraction.png?fit=300%2C207&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-feature-extraction.png?fit=1024%2C706&amp;ssl=1" src="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-feature-extraction-1024x706.png?resize=840%2C579&#038;ssl=1" alt="BERT feature extraction" class="wp-image-45974" width="840" height="579" data-recalc-dims="1"  /></noscript><figcaption><em><a href="http://jalammar.github.io/illustrated-bert/" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p>In the original BERT paper, it was compared with GPT on the <a href="https://gluebenchmark.com/" target="_blank" rel="noreferrer noopener nofollow">General Language understanding evaluation benchmark</a>, and here are the results.&nbsp;</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img data-attachment-id="45975" data-permalink="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial/attachment/bert-gpt-comparison" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-GPT-comparison.png?fit=1600%2C386&amp;ssl=1" data-orig-size="1600,386" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BERT-GPT-comparison" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-GPT-comparison.png?fit=300%2C72&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-GPT-comparison.png?fit=1024%2C247&amp;ssl=1" width="1024" height="247" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/BERT-GPT-comparison.png" alt="BERT GPT comparison" class="wp-image-45975 jetpack-lazy-image jetpack-lazy-image--handled" data-recalc-dims="1" data-lazy-loaded="1" loading="eager"><noscript><img data-lazy-fallback="1" data-attachment-id="45975" data-permalink="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial/attachment/bert-gpt-comparison" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-GPT-comparison.png?fit=1600%2C386&amp;ssl=1" data-orig-size="1600,386" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BERT-GPT-comparison" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-GPT-comparison.png?fit=300%2C72&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-GPT-comparison.png?fit=1024%2C247&amp;ssl=1" width="1024" height="247" src="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-GPT-comparison.png?resize=1024%2C247&#038;ssl=1" alt="BERT GPT comparison" class="wp-image-45975" data-recalc-dims="1" /></noscript><figcaption><a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank" rel="noreferrer noopener nofollow"><em>Source</em></a></figcaption></figure></div>



<p>As you can see BERT outperformed GPT in all the tasks and averages 7% better than GPT.</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img data-attachment-id="45976" data-permalink="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial/attachment/bert-tasks" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-tasks.png?fit=1018%2C978&amp;ssl=1" data-orig-size="1018,978" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BERT-tasks" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-tasks.png?fit=300%2C288&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-tasks.png?fit=1018%2C978&amp;ssl=1" width="1018" height="978" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/BERT-tasks.png" alt="BERT tasks" class="wp-image-45976 jetpack-lazy-image jetpack-lazy-image--handled" data-recalc-dims="1" data-lazy-loaded="1" loading="eager"><noscript><img data-lazy-fallback="1" data-attachment-id="45976" data-permalink="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial/attachment/bert-tasks" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-tasks.png?fit=1018%2C978&amp;ssl=1" data-orig-size="1018,978" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BERT-tasks" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-tasks.png?fit=300%2C288&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-tasks.png?fit=1018%2C978&amp;ssl=1" width="1018" height="978" src="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-tasks.png?resize=1018%2C978&#038;ssl=1" alt="BERT tasks" class="wp-image-45976" data-recalc-dims="1" /></noscript><figcaption><em>The image above shows the different tasks that BERT can be used for.&nbsp;| <a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<h2>Coding BERT with Pytorch</h2>



<p>Let’s understand with code how to build BERT with PyTorch.&nbsp;</p>



<p>We will break the entire program into 4 sections:</p>


<div class="custom-point-list">
<ol><li>Preprocessing</li><li>Building model</li><li>Loss and Optimization</li><li>Training</li></ol>
</div>


<div id="blog-cta-intext-block_60a29af8ac11d" class="blog-cta-intext">
  <h3 class="blog-cta-intext__title">Check also</h3>
  <div class="blog-cta-intext__content"><p><a href="https://neptune.ai/blog/how-to-keep-track-of-experiments-in-pytorch-using-neptune" target="_blank" rel="noopener">How to Keep Track of Experiments in PyTorch Using Neptune</a></p>
</div>
  </div>


<h3>Preprocessing</h3>



<p>In preprocessing we will structure the data such that the neural network can process it. We start by assigning a raw text for training.&nbsp;</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><div>text = (
       <span class="hljs-string" style="color: rgb(221, 17, 68);">'Hello, how are you? I am Romeo.\n'</span>
       <span class="hljs-string" style="color: rgb(221, 17, 68);">'Hello, Romeo My name is Juliet. Nice to meet you.\n'</span>
       <span class="hljs-string" style="color: rgb(221, 17, 68);">'Nice meet you too. How are you today?\n'</span>
       <span class="hljs-string" style="color: rgb(221, 17, 68);">'Great. My baseball team won the competition.\n'</span>
       <span class="hljs-string" style="color: rgb(221, 17, 68);">'Oh Congratulations, Juliet\n'</span>
       <span class="hljs-string" style="color: rgb(221, 17, 68);">'Thanks you Romeo'</span>
   )</div></pre>



<p>Then we will clean the data by:</p>


<div class="custom-point-list">
<ul><li>Making the sentences into lower case.</li><li>Creating vocabulary. <strong>Vocabulary</strong> is a list of unique words in the document.&nbsp;</li></ul>
</div>


<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><div>  sentences = re.sub(<span class="hljs-string" style="color: rgb(221, 17, 68);">"[.,!?\\-]"</span>, <span class="hljs-string" style="color: rgb(221, 17, 68);">''</span>, text.lower()).split(<span class="hljs-string" style="color: rgb(221, 17, 68);">'\n'</span>)  <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># filter '.', ',', '?', '!'</span>
   word_list = list(set(<span class="hljs-string" style="color: rgb(221, 17, 68);">" "</span>.join(sentences).split()))
</div></pre>



<p>Now, in the following step, it is important to remember that BERT takes special tokens during training. Here is a table explaining the purpose of various tokens:</p>


<div id="block_61af510f81cd3" class="separator separator-10"></div>


<div class="medium-table">
        <div class="mt-row heading">
            <div class="mt-col" style="width: 20%">
            Token        </div>
            <div class="mt-col" style="width: 80%">
            Purpose        </div>
        </div>
    
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p>[CLS]</p>
                                    </div>
                            <div class="mt-col" style="width: 80%">
                                        <span class="column-name">
                        Purpose:
                    </span>
                                                                <p>The first token is always classification</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p>[SEP]</p>
                                    </div>
                            <div class="mt-col" style="width: 80%">
                                        <span class="column-name">
                        Purpose:
                    </span>
                                                                <p>Separates two sentences</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p>[END]</p>
                                    </div>
                            <div class="mt-col" style="width: 80%">
                                        <span class="column-name">
                        Purpose:
                    </span>
                                                                <p>End the sentence.</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p>[PAD]</p>
                                    </div>
                            <div class="mt-col" style="width: 80%">
                                        <span class="column-name">
                        Purpose:
                    </span>
                                                                <p>Use to truncate the sentence with equal length.</p>
                                    </div>
                    </div>
            <div class="mt-row">
                            <div class="mt-col" style="width: 20%">
                                                                <p>[MASK]</p>
                                    </div>
                            <div class="mt-col" style="width: 80%">
                                        <span class="column-name">
                        Purpose:
                    </span>
                                                                <p>Use to create a mask by replacing the original word.</p>
                                    </div>
                    </div>
    </div>


<div id="block_60a29279ac117" class="separator separator-20"></div>



<p>These tokens should be included in the word dictionary where each token and word in the vocabulary is assigned with an index number.&nbsp;</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><div>word_dict = {<span class="hljs-string" style="color: rgb(221, 17, 68);">'[PAD]'</span>: <span class="hljs-number" style="color: teal;">0</span>, <span class="hljs-string" style="color: rgb(221, 17, 68);">'[CLS]'</span>: <span class="hljs-number" style="color: teal;">1</span>, <span class="hljs-string" style="color: rgb(221, 17, 68);">'[SEP]'</span>: <span class="hljs-number" style="color: teal;">2</span>, <span class="hljs-string" style="color: rgb(221, 17, 68);">'[MASK]'</span>: <span class="hljs-number" style="color: teal;">3</span>}
<span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">for</span> i, w <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">in</span> enumerate(word_list):
   word_dict[w] = i + <span class="hljs-number" style="color: teal;">4</span>
   number_dict = {i: w <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">for</span> i, w <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">in</span> enumerate(word_dict)}
   vocab_size = len(word_dict)</div></pre>



<p>Once that is taken care of, we need to create a function that formats the input sequences for three types of embeddings: <strong>token embedding</strong>, <strong>segment embedding,</strong> and <strong>position embedding</strong>.</p>



<p>What is token embedding?</p>



<p>For instance, if the sentence is “The cat is walking. The dog is barking”, then the function should create a sequence in the following manner: “[CLS] the cat is walking [SEP] the dog is barking”.&nbsp;</p>



<p>After that, we convert everything to an index from the word dictionary. So the previous sentence would look something like “[1, 5, 7, 9, 10, 2, 5, 6, 9, 11]”. Keep in mind that 1 and 2 are [CLS] and [SEP] respectively.&nbsp;</p>



<p><strong>What is segment embedding?</strong></p>



<p>A segment embedding separates two sentences from each other and they are generally defined as 0 and 1.&nbsp;</p>



<p><strong>What is position embedding?</strong></p>



<p>A position embedding gives position to each embedding in a sequence.&nbsp;</p>



<p>We will create a function for position embedding later.&nbsp;</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img data-attachment-id="45977" data-permalink="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial/attachment/bert-embeddings" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-embeddings.png?fit=1566%2C520&amp;ssl=1" data-orig-size="1566,520" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BERT-embeddings" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-embeddings.png?fit=300%2C100&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-embeddings.png?fit=1024%2C340&amp;ssl=1" width="1024" height="340" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/BERT-embeddings-1024x340.png" alt="BERT embeddings" class="wp-image-45977 jetpack-lazy-image jetpack-lazy-image--handled" data-recalc-dims="1" data-lazy-loaded="1" loading="eager"><noscript><img data-lazy-fallback="1" data-attachment-id="45977" data-permalink="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial/attachment/bert-embeddings" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-embeddings.png?fit=1566%2C520&amp;ssl=1" data-orig-size="1566,520" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BERT-embeddings" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-embeddings.png?fit=300%2C100&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-embeddings.png?fit=1024%2C340&amp;ssl=1" width="1024" height="340" src="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-embeddings-1024x340.png?resize=1024%2C340&#038;ssl=1" alt="BERT embeddings" class="wp-image-45977" data-recalc-dims="1" /></noscript><figcaption><a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank" rel="noreferrer noopener nofollow"><em>Source</em></a></figcaption></figure></div>



<p>Now the next step will be to create <strong>masking</strong>.&nbsp;</p>



<p>As mentioned in the original paper, BERT randomly assigns masks to 15% of the sequence. But keep in mind that you don’t assign masks to the special tokens. For that, we will use conditional statements.</p>



<p>Once we replace 15% of the words with [MASK] tokens, we will add padding. Padding is usually done to make sure that all the sentences are of equal length. For instance, if we take the sentence :</p>



<p><em><strong>&nbsp;“The cat is walking. The dog is barking at the tree”</strong></em></p>



<p>then with padding, it will look like this:&nbsp;</p>



<p><em><strong>“[CLS] The cat is walking [PAD] [PAD] [PAD]. [CLS] The dog is barking at the tree.”&nbsp;</strong></em></p>



<p>The length of the first sentence is equal to the length of the second sentence.&nbsp;</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><div><span class="hljs-function"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">def</span> <span class="hljs-title" style="color: rgb(153, 0, 0); font-weight: 700;">make_batch</span><span class="hljs-params">()</span>:</span>
   batch = []
   positive = negative = <span class="hljs-number" style="color: teal;">0</span>
   <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">while</span> positive != batch_size/<span class="hljs-number" style="color: teal;">2</span> <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">or</span> negative != batch_size/<span class="hljs-number" style="color: teal;">2</span>:
       tokens_a_index, tokens_b_index= randrange(len(sentences)), randrange(len(sentences)) 

       tokens_a, tokens_b= token_list[tokens_a_index], token_list[tokens_b_index]

       input_ids = [word_dict[<span class="hljs-string" style="color: rgb(221, 17, 68);">'[CLS]'</span>]] + tokens_a + [word_dict[<span class="hljs-string" style="color: rgb(221, 17, 68);">'[SEP]'</span>]] + tokens_b + [word_dict[<span class="hljs-string" style="color: rgb(221, 17, 68);">'[SEP]'</span>]]


       segment_ids = [<span class="hljs-number" style="color: teal;">0</span>] * (<span class="hljs-number" style="color: teal;">1</span> + len(tokens_a) + <span class="hljs-number" style="color: teal;">1</span>) + [<span class="hljs-number" style="color: teal;">1</span>] * (len(tokens_b) + <span class="hljs-number" style="color: teal;">1</span>)

       <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># MASK LM</span>
       n_pred =  min(max_pred, max(<span class="hljs-number" style="color: teal;">1</span>, int(round(len(input_ids) * <span class="hljs-number" style="color: teal;">0.15</span>)))) <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># 15 % of tokens in one sentence</span>
       cand_maked_pos = [i <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">for</span> i, token <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">in</span> enumerate(input_ids)
                         <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">if</span> token != word_dict[<span class="hljs-string" style="color: rgb(221, 17, 68);">'[CLS]'</span>] <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">and</span> token != word_dict[<span class="hljs-string" style="color: rgb(221, 17, 68);">'[SEP]'</span>]]
       shuffle(cand_maked_pos)
       masked_tokens, masked_pos = [], []
       <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">for</span> pos <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">in</span> cand_maked_pos[:n_pred]:
           masked_pos.append(pos)
           masked_tokens.append(input_ids[pos])
           <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">if</span> random() &lt; <span class="hljs-number" style="color: teal;">0.8</span>:  <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># 80%</span>
               input_ids[pos] = word_dict[<span class="hljs-string" style="color: rgb(221, 17, 68);">'[MASK]'</span>] <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># make mask</span>
           <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">elif</span> random() &lt; <span class="hljs-number" style="color: teal;">0.5</span>:  <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># 10%</span>
               index = randint(<span class="hljs-number" style="color: teal;">0</span>, vocab_size - <span class="hljs-number" style="color: teal;">1</span>) <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># random index in vocabulary</span>
               input_ids[pos] = word_dict[number_dict[index]] <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># replace</span>

       <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># Zero Paddings</span>
       n_pad = maxlen - len(input_ids)
       input_ids.extend([<span class="hljs-number" style="color: teal;">0</span>] * n_pad)
       segment_ids.extend([<span class="hljs-number" style="color: teal;">0</span>] * n_pad)

       <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># Zero Padding (100% - 15%) tokens</span>
       <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">if</span> max_pred &gt; n_pred:
           n_pad = max_pred - n_pred
           masked_tokens.extend([<span class="hljs-number" style="color: teal;">0</span>] * n_pad)
           masked_pos.extend([<span class="hljs-number" style="color: teal;">0</span>] * n_pad)

       <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">if</span> tokens_a_index + <span class="hljs-number" style="color: teal;">1</span> == tokens_b_index <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">and</span> positive &lt; batch_size/<span class="hljs-number" style="color: teal;">2</span>:
           batch.append([input_ids, segment_ids, masked_tokens, masked_pos, <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">True</span>]) <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># IsNext</span>
           positive += <span class="hljs-number" style="color: teal;">1</span>
       <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">elif</span> tokens_a_index + <span class="hljs-number" style="color: teal;">1</span> != tokens_b_index <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">and</span> negative &lt; batch_size/<span class="hljs-number" style="color: teal;">2</span>:
           batch.append([input_ids, segment_ids, masked_tokens, masked_pos, <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">False</span>]) <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># NotNext</span>
           negative += <span class="hljs-number" style="color: teal;">1</span>
   <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">return</span> batch</div></pre>



<p>Since we are dealing with next-word prediction, we have to create a label that predicts whether the sentence has a consecutive sentence or not, i.e. IsNext or NotNext. So we assign True for every sentence that precedes the next sentence and we use a conditional statement to do that.&nbsp;</p>



<p>For instance, two sentences in a document usually follow each other if they are in context. So assuming the first sentence is A then the next sentence should be A+1. Intuitively we write the code such that if the first sentence positions i.e. tokens_a_index + 1 == tokens_b_index,&nbsp; i.e. second sentence in the same context, then we can set the label for this input as True.&nbsp;</p>



<p>If the above condition is not met i.e. if tokens_a_index + 1 != tokens_b_index then we set the label for this input as False.&nbsp;</p>



<h3>Building model</h3>



<p>BERT is a complex model and if it is perceived slowly you lose track of the logic. So it’ll only make sense to explain its component by component and their function.</p>



<p>BERT has the following components:</p>


<div class="custom-point-list">
<ol><li>Embedding layers</li><li>Attention Mask</li><li>Encoder layer<ol><li>Multi-head attention<ol><li>Scaled dot product attention</li></ol></li><li>Position-wise feed-forward network</li></ol></li><li>BERT (assembling all the components)</li></ol>
</div>


<p>To make learning easier you can always refer to this diagram.&nbsp;</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img data-attachment-id="45979" data-permalink="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial/attachment/bert-building-model" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-building-model.png?fit=523%2C653&amp;ssl=1" data-orig-size="523,653" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BERT-building-model" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-building-model.png?fit=240%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-building-model.png?fit=523%2C653&amp;ssl=1" width="523" height="653" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/BERT-building-model.png" alt="BERT building model" class="wp-image-45979 jetpack-lazy-image jetpack-lazy-image--handled" data-recalc-dims="1" data-lazy-loaded="1" loading="eager"><noscript><img data-lazy-fallback="1" data-attachment-id="45979" data-permalink="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial/attachment/bert-building-model" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-building-model.png?fit=523%2C653&amp;ssl=1" data-orig-size="523,653" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BERT-building-model" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-building-model.png?fit=240%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-building-model.png?fit=523%2C653&amp;ssl=1" width="523" height="653" src="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-building-model.png?resize=523%2C653&#038;ssl=1" alt="BERT building model" class="wp-image-45979" data-recalc-dims="1" /></noscript><figcaption><em>Source: Author</em></figcaption></figure></div>



<h4>Embedding layer</h4>



<p>The embedding is the first layer in BERT that takes the input and creates a <em>lookup table</em>. The parameters of the embedding layers are learnable, which means when the learning process is over the embeddings will cluster similar words together.&nbsp;</p>



<p>The embedding layer also preserves different relationships between words such as: semantic, syntactic, linear, and since BERT is bidirectional it will also preserve contextual relationships as well.&nbsp;</p>



<p>In the case of BERT, it creates three embeddings for&nbsp;</p>


<div class="custom-point-list">
<ul><li>Token,&nbsp;</li><li>Segments and</li><li>Position.&nbsp;</li></ul>
</div>


<p>If you recall we haven’t created a function that takes the input and formats it for position embedding but the formatting for token and segments are completed. So we will take the input and create a position for each word in the sequence. And it looks something like this:</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><div>print(torch.arange(<span class="hljs-number" style="color: teal;">30</span>, dtype=torch.long).expand_as(input_ids))</div></pre>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; background: rgb(43, 43, 43); color: rgb(186, 186, 186);"><div>Output:

tensor([[ <span class="hljs-number" style="color: rgb(104, 150, 186);">0</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">1</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">2</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">3</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">4</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">5</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">6</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">7</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">8</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">9</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">10</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">11</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">12</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">13</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">14</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">15</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">16</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">17</span>,
         <span class="hljs-number" style="color: rgb(104, 150, 186);">18</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">19</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">20</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">21</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">22</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">23</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">24</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">25</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">26</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">27</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">28</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">29</span>],
        [ <span class="hljs-number" style="color: rgb(104, 150, 186);">0</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">1</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">2</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">3</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">4</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">5</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">6</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">7</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">8</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">9</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">10</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">11</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">12</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">13</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">14</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">15</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">16</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">17</span>,
         <span class="hljs-number" style="color: rgb(104, 150, 186);">18</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">19</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">20</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">21</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">22</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">23</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">24</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">25</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">26</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">27</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">28</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">29</span>],
        [ <span class="hljs-number" style="color: rgb(104, 150, 186);">0</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">1</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">2</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">3</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">4</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">5</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">6</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">7</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">8</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">9</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">10</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">11</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">12</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">13</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">14</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">15</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">16</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">17</span>,
         <span class="hljs-number" style="color: rgb(104, 150, 186);">18</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">19</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">20</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">21</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">22</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">23</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">24</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">25</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">26</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">27</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">28</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">29</span>],
        [ <span class="hljs-number" style="color: rgb(104, 150, 186);">0</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">1</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">2</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">3</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">4</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">5</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">6</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">7</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">8</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">9</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">10</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">11</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">12</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">13</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">14</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">15</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">16</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">17</span>,
         <span class="hljs-number" style="color: rgb(104, 150, 186);">18</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">19</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">20</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">21</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">22</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">23</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">24</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">25</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">26</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">27</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">28</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">29</span>],
        [ <span class="hljs-number" style="color: rgb(104, 150, 186);">0</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">1</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">2</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">3</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">4</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">5</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">6</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">7</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">8</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">9</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">10</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">11</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">12</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">13</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">14</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">15</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">16</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">17</span>,
         <span class="hljs-number" style="color: rgb(104, 150, 186);">18</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">19</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">20</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">21</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">22</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">23</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">24</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">25</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">26</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">27</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">28</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">29</span>],
        [ <span class="hljs-number" style="color: rgb(104, 150, 186);">0</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">1</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">2</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">3</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">4</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">5</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">6</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">7</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">8</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">9</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">10</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">11</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">12</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">13</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">14</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">15</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">16</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">17</span>,
         <span class="hljs-number" style="color: rgb(104, 150, 186);">18</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">19</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">20</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">21</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">22</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">23</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">24</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">25</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">26</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">27</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">28</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">29</span>]])</div></pre>



<p>In the forward function, we sum up all the embeddings and normalize them.&nbsp;</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img data-attachment-id="45978" data-permalink="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial/attachment/bert-embeddings-2" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-embeddings-2.png?fit=1566%2C520&amp;ssl=1" data-orig-size="1566,520" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BERT-embeddings-2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-embeddings-2.png?fit=300%2C100&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-embeddings-2.png?fit=1024%2C340&amp;ssl=1" width="1024" height="340" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/BERT-embeddings-2.png" alt="BERT embeddings" class="wp-image-45978 jetpack-lazy-image jetpack-lazy-image--handled" data-recalc-dims="1" data-lazy-loaded="1" loading="eager"><noscript><img data-lazy-fallback="1" data-attachment-id="45978" data-permalink="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial/attachment/bert-embeddings-2" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-embeddings-2.png?fit=1566%2C520&amp;ssl=1" data-orig-size="1566,520" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BERT-embeddings-2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-embeddings-2.png?fit=300%2C100&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-embeddings-2.png?fit=1024%2C340&amp;ssl=1" width="1024" height="340" src="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-embeddings-2.png?resize=1024%2C340&#038;ssl=1" alt="BERT embeddings" class="wp-image-45978" data-recalc-dims="1" /></noscript><figcaption><em><a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><div><span class="hljs-class"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">class</span> <span class="hljs-title" style="color: rgb(68, 85, 136); font-weight: 700;">Embedding</span><span class="hljs-params">(nn.Module)</span>:</span>
   <span class="hljs-function"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">def</span> <span class="hljs-title" style="color: rgb(153, 0, 0); font-weight: 700;">__init__</span><span class="hljs-params">(self)</span>:</span>
       super(Embedding, self).__init__()
       self.tok_embed = nn.Embedding(vocab_size, d_model)  <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># token embedding</span>
       self.pos_embed = nn.Embedding(maxlen, d_model)  <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># position embedding</span>
       self.seg_embed = nn.Embedding(n_segments, d_model)  <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># segment(token type) embedding</span>
       self.norm = nn.LayerNorm(d_model)

   <span class="hljs-function"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">def</span> <span class="hljs-title" style="color: rgb(153, 0, 0); font-weight: 700;">forward</span><span class="hljs-params">(self, x, seg)</span>:</span>
       seq_len = x.size(<span class="hljs-number" style="color: teal;">1</span>)
       pos = torch.arange(seq_len, dtype=torch.long)
       pos = pos.unsqueeze(<span class="hljs-number" style="color: teal;">0</span>).expand_as(x)  <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># (seq_len,) -&gt; (batch_size, seq_len)</span>
       embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)
       <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">return</span> self.norm(embedding)</div></pre>



<div id="blog-cta-intext-block_60a29b46ac11e" class="blog-cta-intext">
  <h3 class="blog-cta-intext__title">Read also</h3>
  <div class="blog-cta-intext__content"><p><a href="https://neptune.ai/blog/word-embeddings-deep-dive-into-custom-datasets" target="_blank" rel="noopener">Training, Visualizing, and Understanding Word Embeddings: Deep Dive Into Custom Datasets</a></p>
</div>
  </div>


<h4>Creating attention mask</h4>



<p><a href="https://neptune.ai/blog/unmasking-bert-transformer-model-performance" target="_blank" rel="noreferrer noopener">BERT needs attention masks</a>. And these should be in a proper format. The following code will help you create masks.&nbsp;</p>



<p>It will convert the [PAD] to 1 and elsewhere 0.&nbsp;</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><div><span class="hljs-function"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">def</span> <span class="hljs-title" style="color: rgb(153, 0, 0); font-weight: 700;">get_attn_pad_mask</span><span class="hljs-params">(seq_q, seq_k)</span>:</span>
   batch_size, len_q = seq_q.size()
   batch_size, len_k = seq_k.size()
   <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># eq(zero) is PAD token</span>
   pad_attn_mask = seq_k.data.eq(<span class="hljs-number" style="color: teal;">0</span>).unsqueeze(<span class="hljs-number" style="color: teal;">1</span>)  <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># batch_size x 1 x len_k(=len_q), one is masking</span>
   <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">return</span> pad_attn_mask.expand(batch_size, len_q, len_k)  <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># batch_size x len_q x len_k</span></div></pre>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><div>print(get_attn_pad_mask(input_ids, input_ids)[<span class="hljs-number" style="color: teal;">0</span>][<span class="hljs-number" style="color: teal;">0</span>], input_ids[<span class="hljs-number" style="color: teal;">0</span>])</div></pre>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; background: rgb(43, 43, 43); color: rgb(186, 186, 186);"><div>Output:
(tensor([<span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>, <span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>, <span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>, <span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>, <span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>, <span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>, <span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>, <span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>, <span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>, <span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>,
         <span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>, <span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>, <span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,
          <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>]),
 tensor([ <span class="hljs-number" style="color: rgb(104, 150, 186);">1</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">3</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">26</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">21</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">14</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">16</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">12</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">4</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">2</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">27</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">3</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">22</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">2</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">0</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">0</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">0</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">0</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">0</span>,
          <span class="hljs-number" style="color: rgb(104, 150, 186);">0</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">0</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">0</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">0</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">0</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">0</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">0</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">0</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">0</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">0</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">0</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">0</span>]))</div></pre>



<h4>Encoder</h4>



<p>The encoder has two main components:&nbsp;</p>


<div class="custom-point-list">
<ul><li>Multi-head Attention</li><li>Position-wise feed-forward network.&nbsp;</li></ul>
</div>


<p>The work of the encoder is to find representations and patterns from the input and attention mask.&nbsp;</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><div><span class="hljs-class"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">class</span> <span class="hljs-title" style="color: rgb(68, 85, 136); font-weight: 700;">EncoderLayer</span><span class="hljs-params">(nn.Module)</span>:</span>
   <span class="hljs-function"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">def</span> <span class="hljs-title" style="color: rgb(153, 0, 0); font-weight: 700;">__init__</span><span class="hljs-params">(self)</span>:</span>
       super(EncoderLayer, self).__init__()
       self.enc_self_attn = MultiHeadAttention()
       self.pos_ffn = PoswiseFeedForwardNet()

   <span class="hljs-function"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">def</span> <span class="hljs-title" style="color: rgb(153, 0, 0); font-weight: 700;">forward</span><span class="hljs-params">(self, enc_inputs, enc_self_attn_mask)</span>:</span>
       enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># enc_inputs to same Q,K,V</span>
       enc_outputs = self.pos_ffn(enc_outputs) <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># enc_outputs: [batch_size x len_q x d_model]</span>
       <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">return</span> enc_outputs, attn</div></pre>



<p><strong>Multi-head attention</strong></p>



<p>This is the first of the main components of the encoder.&nbsp;</p>



<p>The attention model takes three inputs: <strong>Query</strong>, <strong>Key,</strong> and <strong>Value</strong>.&nbsp;</p>



<p><em>I highly recommend you to read </em><a href="https://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noreferrer noopener nofollow"><em>The Illustrated Transformer</em></a><em> by Jay Alammar that explains Attention models in depth.&nbsp;</em></p>



<p>Multihead attention takes four inputs: <strong>Query</strong>, <strong>Key</strong>, <strong>Value,</strong> and <strong>Attention mask</strong>. The embeddings are fed as input to the Query, Key, and Value argument, and the attention mask is fed as input to the attention mask argument.&nbsp;<br>These three inputs and the attention mask are operated with a dot product operation that yields two outputs: <strong>context vectors</strong> and <strong>attention</strong>. The context vector is then passed through a linear layer and finally that yields the output.</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><div><span class="hljs-class"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">class</span> <span class="hljs-title" style="color: rgb(68, 85, 136); font-weight: 700;">MultiHeadAttention</span><span class="hljs-params">(nn.Module)</span>:</span>
   <span class="hljs-function"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">def</span> <span class="hljs-title" style="color: rgb(153, 0, 0); font-weight: 700;">__init__</span><span class="hljs-params">(self)</span>:</span>
       super(MultiHeadAttention, self).__init__()
       self.W_Q = nn.Linear(d_model, d_k * n_heads)
       self.W_K = nn.Linear(d_model, d_k * n_heads)
       self.W_V = nn.Linear(d_model, d_v * n_heads)

   <span class="hljs-function"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">def</span> <span class="hljs-title" style="color: rgb(153, 0, 0); font-weight: 700;">forward</span><span class="hljs-params">(self, Q, K, V, attn_mask)</span>:</span>
       <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># q: [batch_size x len_q x d_model], k: [batch_size x len_k x d_model], v: [batch_size x len_k x d_model]</span>
       residual, batch_size = Q, Q.size(<span class="hljs-number" style="color: teal;">0</span>)
       <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># (B, S, D) -proj-&gt; (B, S, D) -split-&gt; (B, S, H, W) -trans-&gt; (B, H, S, W)</span>
       q_s = self.W_Q(Q).view(batch_size, <span class="hljs-number" style="color: teal;">-1</span>, n_heads, d_k).transpose(<span class="hljs-number" style="color: teal;">1</span>,<span class="hljs-number" style="color: teal;">2</span>)  <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># q_s: [batch_size x n_heads x len_q x d_k]</span>
       k_s = self.W_K(K).view(batch_size, <span class="hljs-number" style="color: teal;">-1</span>, n_heads, d_k).transpose(<span class="hljs-number" style="color: teal;">1</span>,<span class="hljs-number" style="color: teal;">2</span>)  <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># k_s: [batch_size x n_heads x len_k x d_k]</span>
       v_s = self.W_V(V).view(batch_size, <span class="hljs-number" style="color: teal;">-1</span>, n_heads, d_v).transpose(<span class="hljs-number" style="color: teal;">1</span>,<span class="hljs-number" style="color: teal;">2</span>)  <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># v_s: [batch_size x n_heads x len_k x d_v]</span>

       attn_mask = attn_mask.unsqueeze(<span class="hljs-number" style="color: teal;">1</span>).repeat(<span class="hljs-number" style="color: teal;">1</span>, n_heads, <span class="hljs-number" style="color: teal;">1</span>, <span class="hljs-number" style="color: teal;">1</span>) <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># attn_mask : [batch_size x n_heads x len_q x len_k]</span>

       <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># context: [batch_size x n_heads x len_q x d_v], attn: [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]</span>
       context, attn = ScaledDotProductAttention()(q_s, k_s, v_s, attn_mask)
       context = context.transpose(<span class="hljs-number" style="color: teal;">1</span>, <span class="hljs-number" style="color: teal;">2</span>).contiguous().view(batch_size, <span class="hljs-number" style="color: teal;">-1</span>, n_heads * d_v) <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># context: [batch_size x len_q x n_heads * d_v]</span>
       output = nn.Linear(n_heads * d_v, d_model)(context)
       

<span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">return</span> nn.LayerNorm(d_model)(output + residual), attn <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># output: [batch_size x len_q x d_model]</span></div></pre>



<p>Now, let’s explore this Scaled Dot Product attention:</p>


<div class="custom-point-list">
<ul><li>The scaled dot product attention class takes four arguments: Query, Key, Value, and Attention mask. Essentially, the first three arguments are fed with the word embeddings and the attention mask argument is fed with attention mask embeddings.</li><li>Then it does a matrix multiplication between <strong>query</strong> and <strong>key</strong> to get scores.&nbsp;</li></ul>
</div>


<p>Following that we use scores.masked_fill_(attn_mask, -1e9) . This attribute fills the element of scores<strong> </strong>with -1e9 where the attention masks are <strong>True</strong> while the rest of the elements get an <strong>attention score</strong> which is then passed through a softmax function that gives a score between 0 and 1. Finally, we perform a matrix multiplication between attention and values which gives us the context vectors.&nbsp;</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><div><span class="hljs-class"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">class</span> <span class="hljs-title" style="color: rgb(68, 85, 136); font-weight: 700;">ScaledDotProductAttention</span><span class="hljs-params">(nn.Module)</span>:</span>
   <span class="hljs-function"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">def</span> <span class="hljs-title" style="color: rgb(153, 0, 0); font-weight: 700;">__init__</span><span class="hljs-params">(self)</span>:</span>
       super(ScaledDotProductAttention, self).__init__()

   <span class="hljs-function"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">def</span> <span class="hljs-title" style="color: rgb(153, 0, 0); font-weight: 700;">forward</span><span class="hljs-params">(self, Q, K, V, attn_mask)</span>:</span>
       scores = torch.matmul(Q, K.transpose(<span class="hljs-number" style="color: teal;">-1</span>, <span class="hljs-number" style="color: teal;">-2</span>)) / np.sqrt(d_k) <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]</span>
       scores.masked_fill_(attn_mask, <span class="hljs-number" style="color: teal;">-1e9</span>) <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># Fills elements of self tensor with value where mask is one.</span>
       attn = nn.Softmax(dim=<span class="hljs-number" style="color: teal;">-1</span>)(scores)
       context = torch.matmul(attn, V)
       <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">return</span> score, context, attn</div></pre>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><div>emb = Embedding()
embeds = emb(input_ids, segment_ids)

attenM = get_attn_pad_mask(input_ids, input_ids)

SDPA= ScaledDotProductAttention()(embeds, embeds, embeds, attenM)

S, C, A = SDPA

print(<span class="hljs-string" style="color: rgb(221, 17, 68);">'Masks'</span>,masks[<span class="hljs-number" style="color: teal;">0</span>][<span class="hljs-number" style="color: teal;">0</span>])
print()
print(<span class="hljs-string" style="color: rgb(221, 17, 68);">'Scores: '</span>, S[<span class="hljs-number" style="color: teal;">0</span>][<span class="hljs-number" style="color: teal;">0</span>],<span class="hljs-string" style="color: rgb(221, 17, 68);">'\n\nAttention Scores after softmax: '</span>, A[<span class="hljs-number" style="color: teal;">0</span>][<span class="hljs-number" style="color: teal;">0</span>])</div></pre>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; background: rgb(43, 43, 43); color: rgb(186, 186, 186);"><div>Output:

Masks tensor([<span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>, <span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>, <span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>, <span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>, <span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>, <span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>, <span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>, <span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>, <span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>, <span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>,
        <span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>, <span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>, <span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,
         <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>,  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span>])

Scores:  tensor([ <span class="hljs-number" style="color: rgb(104, 150, 186);">9.6000e+01</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">3.1570e+01</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">2.9415e+01</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">3.3990e+01</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">3.7752e+01</span>,
         <span class="hljs-number" style="color: rgb(104, 150, 186);">3.7363e+01</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">3.1683e+01</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">3.2156e+01</span>,  <span class="hljs-number" style="color: rgb(104, 150, 186);">3.5942e+01</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">-2.4670e+00</span>,
        <span class="hljs-number" style="color: rgb(104, 150, 186);">-2.2461e+00</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">-8.1908e+00</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">-2.1571e+00</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">-1.0000e+09</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">-1.0000e+09</span>,
        <span class="hljs-number" style="color: rgb(104, 150, 186);">-1.0000e+09</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">-1.0000e+09</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">-1.0000e+09</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">-1.0000e+09</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">-1.0000e+09</span>,
        <span class="hljs-number" style="color: rgb(104, 150, 186);">-1.0000e+09</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">-1.0000e+09</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">-1.0000e+09</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">-1.0000e+09</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">-1.0000e+09</span>,
        <span class="hljs-number" style="color: rgb(104, 150, 186);">-1.0000e+09</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">-1.0000e+09</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">-1.0000e+09</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">-1.0000e+09</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">-1.0000e+09</span>],
       grad_fn=&lt;SelectBackward&gt;) 

Attention Scores after softmax::  tensor([<span class="hljs-number" style="color: rgb(104, 150, 186);">1.0000e+00</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">1.0440e-28</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">1.2090e-29</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">1.1732e-27</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">5.0495e-26</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">3.4218e-26</span>,
        <span class="hljs-number" style="color: rgb(104, 150, 186);">1.1689e-28</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">1.8746e-28</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">8.2677e-27</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">1.7236e-43</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">2.1440e-43</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">0.0000e+00</span>,
        <span class="hljs-number" style="color: rgb(104, 150, 186);">2.3542e-43</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">0.0000e+00</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">0.0000e+00</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">0.0000e+00</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">0.0000e+00</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">0.0000e+00</span>,
        <span class="hljs-number" style="color: rgb(104, 150, 186);">0.0000e+00</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">0.0000e+00</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">0.0000e+00</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">0.0000e+00</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">0.0000e+00</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">0.0000e+00</span>,
        <span class="hljs-number" style="color: rgb(104, 150, 186);">0.0000e+00</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">0.0000e+00</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">0.0000e+00</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">0.0000e+00</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">0.0000e+00</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">0.0000e+00</span>],
       grad_fn=&lt;SelectBackward&gt;)</div></pre>



<p><strong>Position-Wise Feed Forward Network</strong></p>



<p>The output from the multihead goes into the feed-forward network and that concludes the encoder part.</p>



<p>Let’s take a breath and revise what we’ve learned so far:</p>


<div class="custom-point-list">
<ul><li>The input goes into the embedding and as well attention function. Both of which are fed into the encoder which has a multi-head function and a feed-forward network.&nbsp;</li><li>The multi-head function itself has a function that operates the embeddings and attention mask using a dot product operation.&nbsp;</li></ul>
</div>


<div class="wp-block-image"><figure class="aligncenter size-large"><img data-attachment-id="45981" data-permalink="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial/attachment/bert-building-model-2" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-building-model-2.png?fit=520%2C607&amp;ssl=1" data-orig-size="520,607" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BERT-building-model-2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-building-model-2.png?fit=257%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-building-model-2.png?fit=520%2C607&amp;ssl=1" width="520" height="607" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/BERT-building-model-2.png" alt="BERT building model" class="wp-image-45981 jetpack-lazy-image jetpack-lazy-image--handled" data-recalc-dims="1" data-lazy-loaded="1" loading="eager"><noscript><img data-lazy-fallback="1" data-attachment-id="45981" data-permalink="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial/attachment/bert-building-model-2" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-building-model-2.png?fit=520%2C607&amp;ssl=1" data-orig-size="520,607" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BERT-building-model-2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-building-model-2.png?fit=257%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-building-model-2.png?fit=520%2C607&amp;ssl=1" width="520" height="607" src="https://i0.wp.com/neptune.ai/wp-content/uploads/BERT-building-model-2.png?resize=520%2C607&#038;ssl=1" alt="BERT building model" class="wp-image-45981" data-recalc-dims="1" /></noscript><figcaption><em>Source: Author</em></figcaption></figure></div>



<h4>Assembling all the components</h4>



<p>Let’s continue from where we left, i.e. the output from the encoder.</p>



<p>The encoder yields two outputs:&nbsp;</p>


<div class="custom-point-list">
<ul><li>One which comes from the feed-forward layer and&nbsp;</li><li>the Attention mask.&nbsp;</li></ul>
</div>


<p>It’s key to remember that BERT does not explicitly use a decoder. Instead, it uses the output and the attention mask to get the desired result.&nbsp;</p>



<p>Although the decoder section in the transformers is replaced with a shallow network which can be used for classification as shown in the code below.<br>Also, BERT outputs two results: one for the <strong>classifier</strong> and the other for <strong>masked</strong>.</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><div><span class="hljs-class"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">class</span> <span class="hljs-title" style="color: rgb(68, 85, 136); font-weight: 700;">BERT</span><span class="hljs-params">(nn.Module)</span>:</span>
   <span class="hljs-function"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">def</span> <span class="hljs-title" style="color: rgb(153, 0, 0); font-weight: 700;">__init__</span><span class="hljs-params">(self)</span>:</span>
       super(BERT, self).__init__()
       self.embedding = Embedding()
       self.layers = nn.ModuleList([EncoderLayer() <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">for</span> _ <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">in</span> range(n_layers)])
       self.fc = nn.Linear(d_model, d_model)
       self.activ1 = nn.Tanh()
       self.linear = nn.Linear(d_model, d_model)
       self.activ2 = gelu
       self.norm = nn.LayerNorm(d_model)
       self.classifier = nn.Linear(d_model, <span class="hljs-number" style="color: teal;">2</span>)
       <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># decoder is shared with embedding layer</span>
       embed_weight = self.embedding.tok_embed.weight
       n_vocab, n_dim = embed_weight.size()
       self.decoder = nn.Linear(n_dim, n_vocab, bias=<span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">False</span>)
       self.decoder.weight = embed_weight
       self.decoder_bias = nn.Parameter(torch.zeros(n_vocab))

   <span class="hljs-function"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">def</span> <span class="hljs-title" style="color: rgb(153, 0, 0); font-weight: 700;">forward</span><span class="hljs-params">(self, input_ids, segment_ids, masked_pos)</span>:</span>
       output = self.embedding(input_ids, segment_ids)
       enc_self_attn_mask = get_attn_pad_mask(input_ids, input_ids)
       <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">for</span> layer <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">in</span> self.layers:
           output, enc_self_attn = layer(output, enc_self_attn_mask)
       <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># output : [batch_size, len, d_model], attn : [batch_size, n_heads, d_mode, d_model]</span>
       <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># it will be decided by first token(CLS)</span>
       h_pooled = self.activ1(self.fc(output[:, <span class="hljs-number" style="color: teal;">0</span>])) <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># [batch_size, d_model]</span>
       logits_clsf = self.classifier(h_pooled) <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># [batch_size, 2]</span>

       masked_pos = masked_pos[:, :, <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">None</span>].expand(<span class="hljs-number" style="color: teal;">-1</span>, <span class="hljs-number" style="color: teal;">-1</span>, output.size(<span class="hljs-number" style="color: teal;">-1</span>)) <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># [batch_size, max_pred, d_model]</span>

       <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># get masked position from final output of transformer.</span>
       h_masked = torch.gather(output, <span class="hljs-number" style="color: teal;">1</span>, masked_pos) <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># masking position [batch_size, max_pred, d_model]</span>
       h_masked = self.norm(self.activ2(self.linear(h_masked)))
       logits_lm = self.decoder(h_masked) + self.decoder_bias <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># [batch_size, max_pred, n_vocab]</span>

       <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">return</span> logits_lm, logits_clsf</div></pre>



<p>Few things to keep in mind:</p>


<div class="custom-point-list">
<ol><li>You can assign the number of encoders. In the original paper, the base model has 12.&nbsp;</li><li>There are two activation functions: Tanh and GELU(<strong>G</strong>aussian <strong>E</strong>rror <strong>L</strong>inear <strong>U</strong>nit).</li></ol>
</div>


<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><div><span class="hljs-function"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">def</span> <span class="hljs-title" style="color: rgb(153, 0, 0); font-weight: 700;">gelu</span><span class="hljs-params">(x)</span>:</span>
   <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">return</span> x * <span class="hljs-number" style="color: teal;">0.5</span> * (<span class="hljs-number" style="color: teal;">1.0</span> + torch.erf(x / math.sqrt(<span class="hljs-number" style="color: teal;">2.0</span>)))</div></pre>



<h3>Loss and optimization</h3>



<p>Although the original paper calculates the probability distribution over all the vocabulary, we can use a softmax approximation. But a neat way to do it is to use <strong><em>cross-entropy loss</em></strong>. It’s a combination of both <em>softmax</em> and <em>negative log-likelihood</em>.&nbsp;</p>



<p>So while building the model you don’t have to include softmax instead get a clean output from feed-forward neural nets without softmax normalization.&nbsp;</p>



<p>When it comes to optimization we will be using <strong>Adam</strong> optimizer.&nbsp;</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><div>criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=<span class="hljs-number" style="color: teal;">0.001</span>)</div></pre>



<div id="blog-cta-intext-block_60a29bb0ac11f" class="blog-cta-intext">
  <h3 class="blog-cta-intext__title">Related article</h3>
  <div class="blog-cta-intext__content"><p><a href="https://neptune.ai/blog/pytorch-loss-functions" target="_blank" rel="noopener">PyTorch Loss Functions: The Ultimate Guide</a></p>
</div>
  </div>


<h3>Training</h3>



<p>Finally, we’ll start the training.&nbsp;</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><div>model = BERT()
batch = make_batch()
input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(*batch))

   <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">for</span> epoch <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">in</span> range(<span class="hljs-number" style="color: teal;">100</span>):
       optimizer.zero_grad()
       logits_lm, logits_clsf = model(input_ids, segment_ids, masked_pos)
       loss_lm = criterion(logits_lm.transpose(<span class="hljs-number" style="color: teal;">1</span>, <span class="hljs-number" style="color: teal;">2</span>), masked_tokens) <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># for masked LM</span>
       loss_lm = (loss_lm.float()).mean()
       loss_clsf = criterion(logits_clsf, isNext) <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># for sentence classification</span>
       loss = loss_lm + loss_clsf
       <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">if</span> (epoch + <span class="hljs-number" style="color: teal;">1</span>) % <span class="hljs-number" style="color: teal;">10</span> == <span class="hljs-number" style="color: teal;">0</span>:
           print(<span class="hljs-string" style="color: rgb(221, 17, 68);">'Epoch:'</span>, <span class="hljs-string" style="color: rgb(221, 17, 68);">'%04d'</span> % (epoch + <span class="hljs-number" style="color: teal;">1</span>), <span class="hljs-string" style="color: rgb(221, 17, 68);">'cost ='</span>, <span class="hljs-string" style="color: rgb(221, 17, 68);">'{:.6f}'</span>.format(loss))
       loss.backward()
       optimizer.step()

   <span class="hljs-comment" style="color: rgb(153, 153, 136); font-style: italic;"># Predict mask tokens</span>
   input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(batch[<span class="hljs-number" style="color: teal;">0</span>]))
   print(text)
   print([number_dict[w.item()] <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">for</span> w <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">in</span> input_ids[<span class="hljs-number" style="color: teal;">0</span>] <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">if</span> number_dict[w.item()] != <span class="hljs-string" style="color: rgb(221, 17, 68);">'[PAD]'</span>])

   logits_lm, logits_clsf = model(input_ids, segment_ids, masked_pos)
   logits_lm = logits_lm.data.max(<span class="hljs-number" style="color: teal;">2</span>)[<span class="hljs-number" style="color: teal;">1</span>][<span class="hljs-number" style="color: teal;">0</span>].data.numpy()
   print(<span class="hljs-string" style="color: rgb(221, 17, 68);">'masked tokens list : '</span>,[pos.item() <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">for</span> pos <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">in</span> masked_tokens[<span class="hljs-number" style="color: teal;">0</span>] <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">if</span> pos.item() != <span class="hljs-number" style="color: teal;">0</span>])
   print(<span class="hljs-string" style="color: rgb(221, 17, 68);">'predict masked tokens list : '</span>,[pos <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">for</span> pos <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">in</span> logits_lm <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">if</span> pos != <span class="hljs-number" style="color: teal;">0</span>])

   logits_clsf = logits_clsf.data.max(<span class="hljs-number" style="color: teal;">1</span>)[<span class="hljs-number" style="color: teal;">1</span>].data.numpy()[<span class="hljs-number" style="color: teal;">0</span>]
   print(<span class="hljs-string" style="color: rgb(221, 17, 68);">'isNext : '</span>, <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">True</span> <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">if</span> isNext <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">else</span> <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">False</span>)
   print(<span class="hljs-string" style="color: rgb(221, 17, 68);">'predict isNext : '</span>,<span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">True</span> <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">if</span> logits_clsf <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">else</span> <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">False</span>)</div></pre>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; background: rgb(43, 43, 43); color: rgb(186, 186, 186);"><div>Output:

Hello, how are you? I am Romeo.
Hello, Romeo My name <span class="hljs-keyword" style="color: rgb(203, 120, 50);">is</span> Juliet. Nice to meet you.
Nice meet you too. How are you today?
Great. My baseball team won the competition.
Oh Congratulations, Juliet
Thanks you Romeo
[<span class="hljs-string" style="color: rgb(224, 196, 108);">'[CLS]'</span>, <span class="hljs-string" style="color: rgb(224, 196, 108);">'nice'</span>, <span class="hljs-string" style="color: rgb(224, 196, 108);">'meet'</span>, <span class="hljs-string" style="color: rgb(224, 196, 108);">'you'</span>, <span class="hljs-string" style="color: rgb(224, 196, 108);">'too'</span>, <span class="hljs-string" style="color: rgb(224, 196, 108);">'how'</span>, <span class="hljs-string" style="color: rgb(224, 196, 108);">'are'</span>, <span class="hljs-string" style="color: rgb(224, 196, 108);">'you'</span>, <span class="hljs-string" style="color: rgb(224, 196, 108);">'today'</span>, <span class="hljs-string" style="color: rgb(224, 196, 108);">'[SEP]'</span>, <span class="hljs-string" style="color: rgb(224, 196, 108);">'[MASK]'</span>, <span class="hljs-string" style="color: rgb(224, 196, 108);">'congratulations'</span>, <span class="hljs-string" style="color: rgb(224, 196, 108);">'[MASK]'</span>, <span class="hljs-string" style="color: rgb(224, 196, 108);">'[SEP]'</span>]
masked tokens list :  [<span class="hljs-number" style="color: rgb(104, 150, 186);">27</span>, <span class="hljs-number" style="color: rgb(104, 150, 186);">22</span>]
predict masked tokens list :  []
isNext :  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">False</span>
predict isNext :  <span class="hljs-keyword" style="color: rgb(203, 120, 50);">True</span></div></pre>



<p>So that was BERT coding from scratch. If you train it over a large corpus you then you can use the same model for:</p>


<div class="custom-point-list">
<ol><li>Pretraining: use any corpus but with the exact format of input representation as mentioned before.</li><li>Fine-tuning: make sure that you use supervised learning data for it.&nbsp;</li><li>Feature extractor for different tasks, or even topic modeling.&nbsp;</li></ol>
</div>


<p>You can find the complete notebook <a href="https://colab.research.google.com/drive/13FjI_uXaw8JJGjzjVX3qKSLyW9p3b6OV?usp=sharing" target="_blank" rel="noreferrer noopener nofollow">here</a>.</p>



<h2>Is there a way to get a pre-trained model?</h2>



<p>In the original paper, two models were released: BERT-base, and BERT-large. In the article, I showed how you can code BERT from scratch.&nbsp;</p>



<p>Generally, you can download the pre-trained model so that you don’t have to go through these steps. The <a href="https://huggingface.co/" target="_blank" rel="noreferrer noopener nofollow">Huggingface</a> <img draggable="false" role="img" class="emoji" alt="🤗" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/1f917.svg"> library offers this feature you can use the transformer library from Huggingface for PyTorch. The process remains the same.&nbsp;</p>



<p>I have a notebook where I used a pre-trained BERT from Huggingface, you can check it out <a href="https://github.com/Nielspace/BERT/blob/master/BERT%20Text%20Classification%20fine-tuning.ipynb" target="_blank" rel="noreferrer noopener nofollow">here</a>.&nbsp;</p>



<p>When you use a pre-trained model, all you need to do is download the model and then call it inside a class and use a forward method to feed your inputs and masks.</p>



<p>For instance:</p>



<pre class="hljs" style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(51, 51, 51); background: rgb(248, 248, 248);"><div><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">import</span> transformers

<span class="hljs-class"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">class</span> <span class="hljs-title" style="color: rgb(68, 85, 136); font-weight: 700;">BERTClassification</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">def</span> <span class="hljs-title" style="color: rgb(153, 0, 0); font-weight: 700;">__init__</span> <span class="hljs-params">(self)</span>:</span>
        super(BERTClassification, self).__init__()
        self.bert = transformers.BertModel.from_pretrained(<span class="hljs-string" style="color: rgb(221, 17, 68);">'bert-base-cased'</span>)
        self.bert_drop = nn.Dropout(<span class="hljs-number" style="color: teal;">0.4</span>)
        self.out = nn.Linear(<span class="hljs-number" style="color: teal;">768</span>, <span class="hljs-number" style="color: teal;">1</span>)
        
    <span class="hljs-function"><span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">def</span> <span class="hljs-title" style="color: rgb(153, 0, 0); font-weight: 700;">forward</span><span class="hljs-params">(self, ids, mask, token_type_ids)</span>:</span>
        _, pooledOut = self.bert(ids, attention_mask = mask,
                                token_type_ids=token_type_ids)
        bertOut = self.bert_drop(pooledOut)
        output = self.out(bertOut)
        
        <span class="hljs-keyword" style="color: rgb(51, 51, 51); font-weight: 700;">return</span> output</div></pre>



<h2>Final thoughts</h2>



<p>BERT is a very powerful state-of-the-art NLP model. The pre-trained model is trained on a large corpus and you can fine-tune it according to your needs and based on the task on a smaller dataset. The best thing about fine-tuning is that you don’t do it for 1000 epochs, it can mimic SOTA performances even in 3 to 10 epochs depending on the parameters and how well the dataset is processed.&nbsp;</p>



<p>I hope this tutorial was interesting and informative. And I hope you were able to take something out of it.&nbsp;</p>



<h3>Resources</h3>


<div class="custom-point-list">
<ul><li><a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank" rel="noreferrer noopener nofollow">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></li><li><a href="http://jalammar.github.io/illustrated-bert/" target="_blank" rel="noreferrer noopener nofollow">The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)</a></li><li><a href="https://arxiv.org/abs/1802.05365" target="_blank" rel="noreferrer noopener nofollow">Deep contextualized word representations : ELMo</a></li><li><a href="https://arxiv.org/abs/1801.06146" target="_blank" rel="noreferrer noopener nofollow">Universal Language Model Fine-tuning for Text Classification</a></li><li><a href="https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf" target="_blank" rel="noreferrer noopener nofollow">Attention is All you Need: Transformer</a></li><li><a href="http://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noreferrer noopener nofollow">The Illustrated Transformer – Jay Alammar – Visualizing …</a></li><li><a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" target="_blank" rel="noreferrer noopener nofollow">Improving Language Understanding by … – Amazon S3</a>&nbsp;</li></ul>
</div>



<div id="author-box-new-format-block_604218f9077b8" class="article__footer article__author">
  <div class="article__authorImage">
          <img width="193" height="193" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/Nilesh-Barla.png" class="article__authorImage-img jetpack-lazy-image jetpack-lazy-image--handled" alt="Nilesh Barla" data-attachment-id="35510" data-permalink="https://neptune.ai/blog/representation-learning-with-autoencoder/attachment/nilesh-barla" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Nilesh-Barla.png?fit=193%2C193&amp;ssl=1" data-orig-size="193,193" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Nilesh Barla" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Nilesh-Barla.png?fit=193%2C193&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Nilesh-Barla.png?fit=193%2C193&amp;ssl=1" data-lazy-loaded="1" loading="eager">      </div>

  <div class="article__authorContent">
          <h3 class="article__authorContent-name">Nilesh Barla</h3>
    
          <p class="article__authorContent-text">I am the founder of a recent startup perceptronai.net which aims to provide solutions in medical and material science through our deep learning algorithms. I also read and think a lot. And sometimes I put them in a form of a painting or a piece of music. And when I need to catch a breath I go for a run.</p>
    
          <ul class="article__authorSocial">
        <li class="article__authorSocial-single article__authorSocial-name">Follow me on</li>
                  <li class="article__authorSocial-single"><a href="https://twitter.com/nielspace07" class="article__authorSocial-tw" target="_blank"></a></li>
        
                  <li class="article__authorSocial-single"><a href="https://www.linkedin.com/in/nielspace/?originalSubdomain=in" class="article__authorSocial-lk" target="_blank"></a></li>
        
              </ul>
    
  </div>
</div>


<div class="wp-container-1 wp-block-group"><div class="wp-block-group__inner-container">
<hr class="wp-block-separator">



<p class="has-text-color" style="color:#4455a6"><strong>READ NEXT</strong></p>



<h2>10 Things You Need to Know About BERT and the Transformer Architecture That Are Reshaping the AI Landscape</h2>



<p class="has-small-font-size">25 mins read | Author Cathal Horan | Updated May 31st, 2021</p>


<div id="block_5ffc75def9f8e" class="separator separator-10"></div>



<p>Few areas of AI are more exciting than NLP right now. In recent years language models (LM), which can perform human-like linguistic tasks, have evolved to perform better than anyone could have expected.&nbsp;</p>



<p>In fact, they’re performing so well that&nbsp;<a href="https://neptune.ai/blog/ai-limits-can-deep-learning-models-like-bert-ever-understand-language" target="_blank" rel="noreferrer noopener">people are wondering</a>&nbsp;whether they’re reaching a level of&nbsp;<a href="https://chatbotslife.com/is-gpt-3-the-first-artificial-general-intelligence-a7390dca155f" target="_blank" rel="noreferrer noopener">general intelligence</a>, or the evaluation metrics we use to test them just can’t keep up. When technology like this comes along, whether it is electricity, the railway, the internet or the iPhone, one thing is clear – you can’t ignore it. It will end up impacting every part of the modern world.&nbsp;</p>



<p>It’s important to learn about technologies like this, because then you can use them to your advantage. So, let’s learn!&nbsp;</p>



<p>We will cover ten things to show you where this technology came from, how it was developed, how it works, and what to expect from it in the near future. The ten things are:</p>


<div class="custom-point-list">
<ol><li><strong>What is BERT and the transformer, and why do I need to understand it?</strong>&nbsp;Models like BERT are already massively impacting academia and business, so we’ll outline some of the ways these models are used, and clarify some of the terminology around them.</li><li><strong>What did we do before these models?</strong>&nbsp;To understand these models, it’s important to look at the problems in this area and understand how we tackled them before models like BERT came on the scene. This way we can understand the limits of previous models and better appreciate the motivation behind the key design aspects of the Transformer architecture, which underpins most SOTA models like BERT.&nbsp;</li><li><strong>NLPs “ImageNet moment; pre-trained models:</strong>&nbsp;Originally, we all trained our own models, or you had to fully train a model for a specific task. One of the key milestones which enabled the rapid evolution in performance was the creation of pre-trained models which could be used “off-the-shelf” and tuned to your specific task with little effort and data, in a process known as transfer learning. Understanding this is key to seeing why these models have been, and continue to perform well in a range of NLP tasks.&nbsp;&nbsp;</li><li><strong>Understanding the Transformer:</strong>&nbsp;You’ve probably heard of BERT and GPT-3, but what about&nbsp;<a href="https://huggingface.co/transformers/model_doc/roberta.html" target="_blank" rel="noreferrer noopener">RoBERTa</a>,&nbsp;<a href="https://huggingface.co/transformers/model_doc/albert.html" target="_blank" rel="noreferrer noopener">ALBERT</a>,&nbsp;<a href="https://huggingface.co/transformers/model_doc/xlnet.html" target="_blank" rel="noreferrer noopener">XLNet</a>, or the&nbsp;<a href="https://huggingface.co/transformers/model_doc/longformer.html" target="_blank" rel="noreferrer noopener">LONGFORMER</a>,&nbsp;<a href="https://huggingface.co/transformers/model_doc/reformer.html" target="_blank" rel="noreferrer noopener">REFORMER</a>, or&nbsp;<a href="https://huggingface.co/transformers/model_doc/t5.html" target="_blank" rel="noreferrer noopener">T5 Transformer</a>? The amount of new models seems overwhelming, but if you understand the Transformer architecture, you’ll have a window into the internal workings of all of these models. It’s the same as when you understand RDBMS technology, giving you a good handle on software like MySQL, PostgreSQL, SQL Server, or Oracle. The relational model that underpins all of the DBs is the same as the Transformer architecture that underpins our models. Understand that, and RoBERTa or XLNet becomes just the difference between using MySQL or PostgreSQL. It still takes time to learn the nuances of each model, but you have a solid foundation and you’re not starting from scratch.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</li><li><strong>The importance of bidirectionality</strong>: As you’re reading this, you’re not strictly reading from one side to the other. You’re not reading this sentence letter by letter in one direction from one side to the other. Instead, you’re jumping ahead and learning context from the words and letters ahead of where you are right now. It turns out this is a critical feature of the Transformer architecture. The Transformer architecture enables models to process text in a bidirectional manner, from start to finish and from finish to start. This has been central to the limits of previous models which could only process text from start to finish.</li></ol>
</div>

<a class="button continous-post blue-filled" href="https://neptune.ai/blog/bert-and-the-transformer-architecture-reshaping-the-ai-landscape" target="_blank">
    Continue reading -&gt;</a>



<hr class="wp-block-separator">
</div></div>
</div>
      </article>
    </div>

    
      <div class="blogSmall">
      <div class="blogSmall__single">
      <img width="355" height="185" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/Comprehensive-Guide-to-Transformers-High-Quality.jpg" class="blogSmall__single-img wp-post-image jetpack-lazy-image jetpack-lazy-image--handled" alt="Comprehensive Guide to Transformers" data-attachment-id="59112" data-permalink="https://neptune.ai/comprehensive-guide-to-transformers-high-quality" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Comprehensive-Guide-to-Transformers-High-Quality.jpg?fit=1200%2C628&amp;ssl=1" data-orig-size="1200,628" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Comprehensive Guide to Transformers-High-Quality" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Comprehensive-Guide-to-Transformers-High-Quality.jpg?fit=300%2C157&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Comprehensive-Guide-to-Transformers-High-Quality.jpg?fit=1024%2C536&amp;ssl=1" data-lazy-loaded="1" loading="eager">    <div class="blogSmall__content">
    <h3 class="blogSmall__content-title"><strong>Comprehensive Guide to Transformers</strong></h3>
    <p class="blogSmall__content-author">
      <strong>by Ahmed Hashesh</strong>
    </p>
    <a href="https://neptune.ai/blog/comprehensive-guide-to-transformers" class="blogSmall__single-link"><span>Read more</span></a>
  </div>
  <a href="https://neptune.ai/blog/comprehensive-guide-to-transformers" class="blogSmall__url"></a>
</div><div class="blogSmall__single">
      <img width="355" height="185" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/Data-Augmentation-in-NLP-Best-Practices-From-a-Kaggle-Master.jpg" class="blogSmall__single-img wp-post-image jetpack-lazy-image jetpack-lazy-image--handled" alt="Data Augmentation in NLP: Best Practices From a Kaggle Master" data-attachment-id="55659" data-permalink="https://neptune.ai/data-augmentation-in-nlp-best-practices-from-a-kaggle-master" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Data-Augmentation-in-NLP-Best-Practices-From-a-Kaggle-Master.jpg?fit=1200%2C628&amp;ssl=1" data-orig-size="1200,628" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Data Augmentation in NLP: Best Practices From a Kaggle Master" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Data-Augmentation-in-NLP-Best-Practices-From-a-Kaggle-Master.jpg?fit=300%2C157&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Data-Augmentation-in-NLP-Best-Practices-From-a-Kaggle-Master.jpg?fit=1024%2C536&amp;ssl=1" data-lazy-loaded="1" loading="eager">    <div class="blogSmall__content">
    <h3 class="blogSmall__content-title"><strong>Data Augmentation in NLP: Best Practices From a Kaggle Master</strong></h3>
    <p class="blogSmall__content-author">
      <strong>by Shahul ES</strong>
    </p>
    <a href="https://neptune.ai/blog/data-augmentation-nlp" class="blogSmall__single-link"><span>Read more</span></a>
  </div>
  <a href="https://neptune.ai/blog/data-augmentation-nlp" class="blogSmall__url"></a>
</div><div class="blogSmall__single">
      <img width="355" height="185" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/How-to-Track-Machine-Learning-Model-Metrics-in-Your-Projects.jpg" class="blogSmall__single-img wp-post-image jetpack-lazy-image jetpack-lazy-image--handled" alt="How to Track Machine Learning Model Metrics in Your Projects" data-attachment-id="55625" data-permalink="https://neptune.ai/how-to-track-machine-learning-model-metrics-in-your-projects" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/How-to-Track-Machine-Learning-Model-Metrics-in-Your-Projects.jpg?fit=1200%2C628&amp;ssl=1" data-orig-size="1200,628" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="How to Track Machine Learning Model Metrics in Your Projects" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/How-to-Track-Machine-Learning-Model-Metrics-in-Your-Projects.jpg?fit=300%2C157&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/How-to-Track-Machine-Learning-Model-Metrics-in-Your-Projects.jpg?fit=1024%2C536&amp;ssl=1" data-lazy-loaded="1" loading="eager">    <div class="blogSmall__content">
    <h3 class="blogSmall__content-title"><strong>How to Track Machine Learning Model Metrics in Your Projects</strong></h3>
    <p class="blogSmall__content-author">
      <strong>by Jakub Czakon</strong>
    </p>
    <a href="https://neptune.ai/blog/how-to-track-machine-learning-model-metrics" class="blogSmall__single-link"><span>Read more</span></a>
  </div>
  <a href="https://neptune.ai/blog/how-to-track-machine-learning-model-metrics" class="blogSmall__url"></a>
</div><div class="blogSmall__single">
      <img width="355" height="185" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/8-Creators-and-Core-Contributors-Talk-About-Their-Model-Training-Libraries-From-PyTorch-Ecosystem.jpg" class="blogSmall__single-img wp-post-image jetpack-lazy-image jetpack-lazy-image--handled" alt="8 Creators and Core Contributors Talk About Their Model Training Libraries From PyTorch Ecosystem" data-attachment-id="54651" data-permalink="https://neptune.ai/8-creators-and-core-contributors-talk-about-their-model-training-libraries-from-pytorch-ecosystem" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/8-Creators-and-Core-Contributors-Talk-About-Their-Model-Training-Libraries-From-PyTorch-Ecosystem.jpg?fit=1200%2C628&amp;ssl=1" data-orig-size="1200,628" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="8 Creators and Core Contributors Talk About Their Model Training Libraries From PyTorch Ecosystem" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/8-Creators-and-Core-Contributors-Talk-About-Their-Model-Training-Libraries-From-PyTorch-Ecosystem.jpg?fit=300%2C157&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/8-Creators-and-Core-Contributors-Talk-About-Their-Model-Training-Libraries-From-PyTorch-Ecosystem.jpg?fit=1024%2C536&amp;ssl=1" data-lazy-loaded="1" loading="eager">    <div class="blogSmall__content">
    <h3 class="blogSmall__content-title"><strong>8 Creators and Core Contributors Talk About Their Model Training Libraries From PyTorch Ecosystem</strong></h3>
    <p class="blogSmall__content-author">
      <strong>by Jakub Czakon</strong>
    </p>
    <a href="https://neptune.ai/blog/model-training-libraries-pytorch-ecosystem" class="blogSmall__single-link"><span>Read more</span></a>
  </div>
  <a href="https://neptune.ai/blog/model-training-libraries-pytorch-ecosystem" class="blogSmall__url"></a>
</div>    </div>
  

  </section>


</main>
<footer class="footer-new">
    <div class="container">
        <div class="footer-container">
            <div class="footer-description">

                <div class="newsletter-container footer-newsletter">
                    <h3>Newsletter</h3>
                    <p class="before-newsletter">
                                                Top MLOps articles, case studies, events (and more) in your inbox every month.<!--                        Top MLOps articles from our blog in your inbox every month.-->
                    </p>
                    <form action="https://neptune.us19.list-manage.com/subscribe?u=8da2bdd288186da3ffeec5626&amp;id=59d3dc2c24" method="post" target="_blank" class="newsletter-horizontal__form">
                        <input type="email" name="EMAIL" placeholder="Type your email here" class="newsletterNew__form-email">
                        <input type="submit" value="Get Newsletter" class="newsletterNew__form-button">
                    </form>
                    <p class="after-newsletter">
                        <!--                        --><!--                        Neptune is a metadata store for MLOps, built for research and production teams that run a lot of experiments.-->
                    </p>
                </div>
                <p>Neptune is a metadata store for MLOps, built for research and production teams that run a lot of experiments.</p>

                                    <ul class="social">
                                                    <li>
                                <a href="https://www.linkedin.com/company/neptuneai">
                                    <img width="30" height="30" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/in.png" class="social-img jetpack-lazy-image jetpack-lazy-image--handled" alt="" data-attachment-id="772" data-permalink="https://neptune.ai/in" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/in.png?fit=30%2C30&amp;ssl=1" data-orig-size="30,30" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="in" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/in.png?fit=30%2C30&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/in.png?fit=30%2C30&amp;ssl=1" data-lazy-loaded="1" loading="eager">                                </a>
                            </li>
                                                    <li>
                                <a href="https://twitter.com/neptune_ai">
                                    <img width="30" height="30" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/tw.png" class="social-img jetpack-lazy-image jetpack-lazy-image--handled" alt="" data-attachment-id="773" data-permalink="https://neptune.ai/tw" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/tw.png?fit=30%2C30&amp;ssl=1" data-orig-size="30,30" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="tw" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/tw.png?fit=30%2C30&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/tw.png?fit=30%2C30&amp;ssl=1" data-lazy-loaded="1" loading="eager">                                </a>
                            </li>
                                                    <li>
                                <a href="https://www.facebook.com/neptuneAI">
                                    <img width="30" height="30" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/fb.png" class="social-img jetpack-lazy-image jetpack-lazy-image--handled" alt="" data-attachment-id="775" data-permalink="https://neptune.ai/fb" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/fb.png?fit=30%2C30&amp;ssl=1" data-orig-size="30,30" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fb" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/fb.png?fit=30%2C30&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/fb.png?fit=30%2C30&amp;ssl=1" data-lazy-loaded="1" loading="eager">                                </a>
                            </li>
                                                    <li>
                                <a href="https://github.com/neptune-ai">
                                    <img width="30" height="30" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/Github-bottom-logo.svg" class="social-img jetpack-lazy-image jetpack-lazy-image--handled" alt="" data-attachment-id="40868" data-permalink="https://neptune.ai/github-bottom-logo" data-orig-file="https://neptune.ai/wp-content/uploads/Github-bottom-logo.svg" data-orig-size="30,30" data-comments-opened="0" data-image-meta="[]" data-image-title="Github bottom logo" data-image-description="" data-image-caption="" data-medium-file="https://neptune.ai/wp-content/uploads/Github-bottom-logo.svg" data-large-file="https://neptune.ai/wp-content/uploads/Github-bottom-logo.svg" data-lazy-loaded="1" loading="eager">                                </a>
                            </li>
                                                    <li>
                                <a href="https://www.youtube.com/channel/UCvOJU-ubyUqxGSDRN7xK4Ng">
                                    <img width="30" height="30" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/YT-icon.png" class="social-img jetpack-lazy-image jetpack-lazy-image--handled" alt="" data-attachment-id="60731" data-permalink="https://neptune.ai/yt-icon" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/YT-icon.png?fit=30%2C30&amp;ssl=1" data-orig-size="30,30" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="YT-icon" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/YT-icon.png?fit=30%2C30&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/YT-icon.png?fit=30%2C30&amp;ssl=1" data-lazy-loaded="1" loading="eager">                                </a>
                            </li>
                                            </ul>
                
            </div>
            <div class="footer-menu-container">
                                    <div class="desktop-menu">
                        <div class="footer-menu-npt"><h3>Product</h3><div class="menu-product-container"><ul id="menu-product" class="menu"><li id="menu-item-70386" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-70386"><a href="https://neptune.ai/product">Overview</a></li>
<li id="menu-item-38779" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-38779"><a href="https://neptune.ai/product/experiment-tracking">Experiment Tracking</a></li>
<li id="menu-item-68643" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-68643"><a href="https://neptune.ai/product/model-registry">Model Registry</a></li>
<li id="menu-item-36798" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-36798"><a href="https://docs.neptune.ai/getting-started/hello-world">Quickstart</a></li>
<li id="menu-item-68648" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-68648"><a href="https://docs.neptune.ai/">Neptune Docs</a></li>
<li id="menu-item-36799" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-36799"><a href="https://docs.neptune.ai/integrations-and-supported-tools/intro">Neptune Integrations</a></li>
<li id="menu-item-68660" class="menu-item menu-item-type-post_type_archive menu-item-object-library menu-item-68660"><a href="https://neptune.ai/resources">Resources</a></li>
<li id="menu-item-68644" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-68644"><a href="https://neptune.ai/pricing">Pricing</a></li>
<li id="menu-item-36795" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-36795"><a target="_blank" rel="noopener" href="https://portal.neptune.ai/">Roadmap</a></li>
<li id="menu-item-36796" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-36796"><a target="_blank" rel="noopener" href="https://status.neptune.ai/">Service Status</a></li>
</ul></div></div>                    </div>
                                            <div class="mobile-menu">
                            <div class="footer-menu-npt"><h3>Product</h3><div class="menu-product-container"><ul id="menu-product-1" class="menu"><li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-70386"><a href="https://neptune.ai/product">Overview</a></li>
<li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-38779"><a href="https://neptune.ai/product/experiment-tracking">Experiment Tracking</a></li>
<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-68643"><a href="https://neptune.ai/product/model-registry">Model Registry</a></li>
<li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-36798"><a href="https://docs.neptune.ai/getting-started/hello-world">Quickstart</a></li>
<li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-68648"><a href="https://docs.neptune.ai/">Neptune Docs</a></li>
<li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-36799"><a href="https://docs.neptune.ai/integrations-and-supported-tools/intro">Neptune Integrations</a></li>
<li class="menu-item menu-item-type-post_type_archive menu-item-object-library menu-item-68660"><a href="https://neptune.ai/resources">Resources</a></li>
<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-68644"><a href="https://neptune.ai/pricing">Pricing</a></li>
<li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-36795"><a target="_blank" rel="noopener" href="https://portal.neptune.ai/">Roadmap</a></li>
<li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-36796"><a target="_blank" rel="noopener" href="https://status.neptune.ai/">Service Status</a></li>
</ul></div></div><div class="footer-menu-npt"><h3>Legal</h3><div class="menu-legal-container"><ul id="menu-legal" class="menu"><li id="menu-item-21345" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-21345"><a href="https://neptune.ai/terms-of-service.pdf">Terms of service</a></li>
<li id="menu-item-21346" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-21346"><a href="https://neptune.ai/privacy-policy.pdf">Privacy policy</a></li>
</ul></div></div>                        </div>
                                                        <div class="desktop-menu">
                        <div class="footer-menu-npt"><h3>Legal</h3><div class="menu-legal-container"><ul id="menu-legal-1" class="menu"><li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-21345"><a href="https://neptune.ai/terms-of-service.pdf">Terms of service</a></li>
<li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-21346"><a href="https://neptune.ai/privacy-policy.pdf">Privacy policy</a></li>
</ul></div></div><div class="footer-menu-npt"><h3>Resources</h3><div class="menu-resources-container"><ul id="menu-resources" class="menu"><li id="menu-item-68646" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-68646"><a href="https://neptune.ai/events">MLOps Live</a></li>
<li id="menu-item-21348" class="menu-item menu-item-type-post_type menu-item-object-page current_page_parent menu-item-21348"><a href="https://neptune.ai/blog">MLOps Blog</a></li>
<li id="menu-item-68647" class="menu-item menu-item-type-post_type menu-item-object-post menu-item-68647"><a href="https://neptune.ai/blog/ml-metadata-store">ML Metadata Store</a></li>
<li id="menu-item-21350" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-21350"><a href="https://neptune.ai/blog/ml-experiment-tracking">ML Experiment Tracking</a></li>
<li id="menu-item-68645" class="menu-item menu-item-type-post_type menu-item-object-post menu-item-68645"><a href="https://neptune.ai/blog/ml-model-registry">ML Model Registry</a></li>
<li id="menu-item-21351" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-21351"><a href="https://neptune.ai/blog/mlops">MLOps</a></li>
<li id="menu-item-68661" class="menu-item menu-item-type-post_type menu-item-object-post menu-item-68661"><a href="https://neptune.ai/blog/mlops-at-reasonable-scale">MLOps at a Reasonable Scale</a></li>
</ul></div></div>                    </div>
                                            <div class="mobile-menu">
                            <div class="footer-menu-npt"><h3>Resources</h3><div class="menu-resources-container"><ul id="menu-resources-1" class="menu"><li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-68646"><a href="https://neptune.ai/events">MLOps Live</a></li>
<li class="menu-item menu-item-type-post_type menu-item-object-page current_page_parent menu-item-21348"><a href="https://neptune.ai/blog">MLOps Blog</a></li>
<li class="menu-item menu-item-type-post_type menu-item-object-post menu-item-68647"><a href="https://neptune.ai/blog/ml-metadata-store">ML Metadata Store</a></li>
<li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-21350"><a href="https://neptune.ai/blog/ml-experiment-tracking">ML Experiment Tracking</a></li>
<li class="menu-item menu-item-type-post_type menu-item-object-post menu-item-68645"><a href="https://neptune.ai/blog/ml-model-registry">ML Model Registry</a></li>
<li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-21351"><a href="https://neptune.ai/blog/mlops">MLOps</a></li>
<li class="menu-item menu-item-type-post_type menu-item-object-post menu-item-68661"><a href="https://neptune.ai/blog/mlops-at-reasonable-scale">MLOps at a Reasonable Scale</a></li>
</ul></div></div><div class="footer-menu-npt"><h3>Competitor Comparison</h3><div class="menu-competitor-comparison-container"><ul id="menu-competitor-comparison" class="menu"><li id="menu-item-36800" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-36800"><a href="https://neptune.ai/blog/best-ml-experiment-tracking-tools">ML Experiment Tracking Tools</a></li>
<li id="menu-item-21341" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-21341"><a href="https://neptune.ai/vs/wandb">Neptune vs Weights &amp; Biases</a></li>
<li id="menu-item-21339" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-21339"><a href="https://neptune.ai/vs/mlflow">Neptune vs MLflow</a></li>
<li id="menu-item-21340" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-21340"><a href="https://neptune.ai/vs/tensorboard">Neptune vs TensorBoard</a></li>
<li id="menu-item-21342" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-21342"><a href="https://neptune.ai/vs">Other Comparisons</a></li>
<li id="menu-item-61948" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-61948"><a href="https://neptune.ai/blog/the-best-mlflow-alternatives">Best MLflow Alternatives</a></li>
<li id="menu-item-61949" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-61949"><a href="https://neptune.ai/blog/the-best-tensorboard-alternatives">Best TensorBoard Alternatives</a></li>
</ul></div></div><div class="footer-menu-npt"><h3>Company</h3><div class="menu-company-container"><ul id="menu-company" class="menu"><li id="menu-item-21334" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-21334"><a href="https://neptune.ai/about-us">About us</a></li>
<li id="menu-item-21335" class="has-badge menu-item menu-item-type-post_type menu-item-object-page menu-item-21335"><a href="https://neptune.ai/jobs">Careers</a></li>
</ul></div></div>                        </div>
                                                        <div class="desktop-menu">
                        <div class="footer-menu-npt"><h3>Competitor Comparison</h3><div class="menu-competitor-comparison-container"><ul id="menu-competitor-comparison-1" class="menu"><li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-36800"><a href="https://neptune.ai/blog/best-ml-experiment-tracking-tools">ML Experiment Tracking Tools</a></li>
<li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-21341"><a href="https://neptune.ai/vs/wandb">Neptune vs Weights &amp; Biases</a></li>
<li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-21339"><a href="https://neptune.ai/vs/mlflow">Neptune vs MLflow</a></li>
<li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-21340"><a href="https://neptune.ai/vs/tensorboard">Neptune vs TensorBoard</a></li>
<li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-21342"><a href="https://neptune.ai/vs">Other Comparisons</a></li>
<li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-61948"><a href="https://neptune.ai/blog/the-best-mlflow-alternatives">Best MLflow Alternatives</a></li>
<li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-61949"><a href="https://neptune.ai/blog/the-best-tensorboard-alternatives">Best TensorBoard Alternatives</a></li>
</ul></div></div><div class="footer-menu-npt"><h3>Company</h3><div class="menu-company-container"><ul id="menu-company-1" class="menu"><li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-21334"><a href="https://neptune.ai/about-us">About us</a></li>
<li class="has-badge menu-item menu-item-type-post_type menu-item-object-page menu-item-21335"><a href="https://neptune.ai/jobs">Careers</a></li>
</ul></div></div>                    </div>
                                                </div>
        </div>
        <div class="copyright">
                            <div class="logo">
                    <img width="47" height="30" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/footer-logo.svg" class="logo--footer-img jetpack-lazy-image jetpack-lazy-image--handled" alt="" data-attachment-id="767" data-permalink="https://neptune.ai/footer-logo" data-orig-file="https://neptune.ai/wp-content/uploads/footer-logo.svg" data-orig-size="47,30" data-comments-opened="1" data-image-meta="[]" data-image-title="footer-logo" data-image-description="" data-image-caption="" data-medium-file="https://neptune.ai/wp-content/uploads/footer-logo.svg" data-large-file="https://neptune.ai/wp-content/uploads/footer-logo.svg" data-lazy-loaded="1" loading="eager">                </div>
                        <p>Copyright © 2022 Neptune Labs. All rights reserved.</p>
        </div>
    </div>
</footer>

<!--  -->
<script defer="" id="bilmur" data-provider="wordpress.com" data-service="atomic" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/bilmur.min.js"></script>
<!--googleoff: all--><div id="cookie-law-info-bar" data-nosnippet="true" style="background-color: rgb(255, 255, 255); color: rgb(204, 213, 255); font-family: inherit; bottom: 0px; position: fixed; display: block;"><span><div class="neptune-cookies">Neptune.ai uses cookies to ensure you get the best experience on this website. By continuing you agree to our use of cookies. <a href="https://neptune.ai/wp-content/uploads/privacy-policy.pdf" target="_blank">Learn more</a> <a role="button" data-cli_action="accept" id="cookie_action_close_header" class="medium cli-plugin-button cli-plugin-main-button cookie_action_close_header cli_action_button wt-cli-accept-btn" style="color: rgb(255, 255, 255); background-color: rgb(0, 185, 120);">Got it!</a></div></span></div><div id="cookie-law-info-again" data-nosnippet="true" style="background-color: rgb(255, 255, 255); color: rgb(204, 213, 255); position: fixed; font-family: inherit; width: auto; bottom: 0px; right: 100px; display: none;"><span id="cookie_hdr_showagain">Manage consent</span></div><div class="cli-modal" data-nosnippet="true" id="cliSettingsPopup" tabindex="-1" role="dialog" aria-labelledby="cliSettingsPopup" aria-hidden="true">
  <div class="cli-modal-dialog" role="document">
	<div class="cli-modal-content cli-bar-popup">
		  <button type="button" class="cli-modal-close" id="cliModalClose">
			<svg class="" viewBox="0 0 24 24"><path d="M19 6.41l-1.41-1.41-5.59 5.59-5.59-5.59-1.41 1.41 5.59 5.59-5.59 5.59 1.41 1.41 5.59-5.59 5.59 5.59 1.41-1.41-5.59-5.59z"></path><path d="M0 0h24v24h-24z" fill="none"></path></svg>
			<span class="wt-cli-sr-only">Close</span>
		  </button>
		  <div class="cli-modal-body">
			<div class="cli-container-fluid cli-tab-container">
	<div class="cli-row">
		<div class="cli-col-12 cli-align-items-stretch cli-px-0">
			<div class="cli-privacy-overview">
				<h4>Privacy Overview</h4>				<div class="cli-privacy-content">
					<div class="cli-privacy-content-text">This website uses cookies to improve your experience while you navigate through the website. Out of these, the cookies that are categorized as necessary are stored on your browser as they are essential for the working of basic functionalities of the ...</div>
				</div>
				<a class="cli-privacy-readmore" aria-label="Show more" role="button" data-readmore-text="Show more" data-readless-text="Show less"></a>			</div>
		</div>
		<div class="cli-col-12 cli-align-items-stretch cli-px-0 cli-tab-section-container">
												<div class="cli-tab-section">
						<div class="cli-tab-header">
							<a role="button" tabindex="0" class="cli-nav-link cli-settings-mobile" data-target="necessary" data-toggle="cli-toggle-tab" data-original-title="" title="">
								Necessary							</a>
															<div class="wt-cli-necessary-checkbox">
									<input type="checkbox" class="cli-user-preference-checkbox" id="wt-cli-checkbox-necessary" data-id="checkbox-necessary" checked="checked">
									<label class="form-check-label" for="wt-cli-checkbox-necessary">Necessary</label>
								</div>
								<span class="cli-necessary-caption">Always Enabled</span>
													</div>
						<div class="cli-tab-content">
							<div class="cli-tab-pane cli-fade" data-id="necessary">
								<div class="wt-cli-cookie-description">
									Necessary cookies are absolutely essential for the website to function properly. These cookies ensure basic functionalities and security features of the website, anonymously.
<table class="cookielawinfo-row-cat-table cookielawinfo-winter"><thead><tr><th class="cookielawinfo-column-1">Cookie</th><th class="cookielawinfo-column-3">Duration</th><th class="cookielawinfo-column-4">Description</th></tr></thead><tbody><tr class="cookielawinfo-row"><td class="cookielawinfo-column-1">cookielawinfo-checbox-analytics</td><td class="cookielawinfo-column-3">11 months</td><td class="cookielawinfo-column-4">This cookie is set by GDPR Cookie Consent plugin. The cookie is used to store the user consent for the cookies in the category "Analytics".</td></tr><tr class="cookielawinfo-row"><td class="cookielawinfo-column-1">cookielawinfo-checbox-functional</td><td class="cookielawinfo-column-3">11 months</td><td class="cookielawinfo-column-4">The cookie is set by GDPR cookie consent to record the user consent for the cookies in the category "Functional".</td></tr><tr class="cookielawinfo-row"><td class="cookielawinfo-column-1">cookielawinfo-checbox-others</td><td class="cookielawinfo-column-3">11 months</td><td class="cookielawinfo-column-4">This cookie is set by GDPR Cookie Consent plugin. The cookie is used to store the user consent for the cookies in the category "Other.</td></tr><tr class="cookielawinfo-row"><td class="cookielawinfo-column-1">cookielawinfo-checkbox-necessary</td><td class="cookielawinfo-column-3">11 months</td><td class="cookielawinfo-column-4">This cookie is set by GDPR Cookie Consent plugin. The cookies is used to store the user consent for the cookies in the category "Necessary".</td></tr><tr class="cookielawinfo-row"><td class="cookielawinfo-column-1">cookielawinfo-checkbox-performance</td><td class="cookielawinfo-column-3">11 months</td><td class="cookielawinfo-column-4">This cookie is set by GDPR Cookie Consent plugin. The cookie is used to store the user consent for the cookies in the category "Performance".</td></tr><tr class="cookielawinfo-row"><td class="cookielawinfo-column-1">viewed_cookie_policy</td><td class="cookielawinfo-column-3">11 months</td><td class="cookielawinfo-column-4">The cookie is set by the GDPR Cookie Consent plugin and is used to store whether or not user has consented to the use of cookies. It does not store any personal data.</td></tr></tbody></table>								</div>
							</div>
						</div>
					</div>
																	<div class="cli-tab-section">
						<div class="cli-tab-header">
							<a role="button" tabindex="0" class="cli-nav-link cli-settings-mobile" data-target="functional" data-toggle="cli-toggle-tab" data-original-title="" title="">
								Functional							</a>
															<div class="cli-switch">
									<input type="checkbox" id="wt-cli-checkbox-functional" class="cli-user-preference-checkbox" data-id="checkbox-functional">
									<label for="wt-cli-checkbox-functional" class="cli-slider" data-cli-enable="Enabled" data-cli-disable="Disabled"><span class="wt-cli-sr-only">Functional</span></label>
								</div>
													</div>
						<div class="cli-tab-content">
							<div class="cli-tab-pane cli-fade" data-id="functional">
								<div class="wt-cli-cookie-description">
									Functional cookies help to perform certain functionalities like sharing the content of the website on social media platforms, collect feedbacks, and other third-party features.
								</div>
							</div>
						</div>
					</div>
																	<div class="cli-tab-section">
						<div class="cli-tab-header">
							<a role="button" tabindex="0" class="cli-nav-link cli-settings-mobile" data-target="performance" data-toggle="cli-toggle-tab" data-original-title="" title="">
								Performance							</a>
															<div class="cli-switch">
									<input type="checkbox" id="wt-cli-checkbox-performance" class="cli-user-preference-checkbox" data-id="checkbox-performance">
									<label for="wt-cli-checkbox-performance" class="cli-slider" data-cli-enable="Enabled" data-cli-disable="Disabled"><span class="wt-cli-sr-only">Performance</span></label>
								</div>
													</div>
						<div class="cli-tab-content">
							<div class="cli-tab-pane cli-fade" data-id="performance">
								<div class="wt-cli-cookie-description">
									Performance cookies are used to understand and analyze the key performance indexes of the website which helps in delivering a better user experience for the visitors.
								</div>
							</div>
						</div>
					</div>
																	<div class="cli-tab-section">
						<div class="cli-tab-header">
							<a role="button" tabindex="0" class="cli-nav-link cli-settings-mobile" data-target="analytics" data-toggle="cli-toggle-tab" data-original-title="" title="">
								Analytics							</a>
															<div class="cli-switch">
									<input type="checkbox" id="wt-cli-checkbox-analytics" class="cli-user-preference-checkbox" data-id="checkbox-analytics">
									<label for="wt-cli-checkbox-analytics" class="cli-slider" data-cli-enable="Enabled" data-cli-disable="Disabled"><span class="wt-cli-sr-only">Analytics</span></label>
								</div>
													</div>
						<div class="cli-tab-content">
							<div class="cli-tab-pane cli-fade" data-id="analytics">
								<div class="wt-cli-cookie-description">
									Analytical cookies are used to understand how visitors interact with the website. These cookies help provide information on metrics the number of visitors, bounce rate, traffic source, etc.
								</div>
							</div>
						</div>
					</div>
																	<div class="cli-tab-section">
						<div class="cli-tab-header">
							<a role="button" tabindex="0" class="cli-nav-link cli-settings-mobile" data-target="advertisement" data-toggle="cli-toggle-tab" data-original-title="" title="">
								Advertisement							</a>
															<div class="cli-switch">
									<input type="checkbox" id="wt-cli-checkbox-advertisement" class="cli-user-preference-checkbox" data-id="checkbox-advertisement">
									<label for="wt-cli-checkbox-advertisement" class="cli-slider" data-cli-enable="Enabled" data-cli-disable="Disabled"><span class="wt-cli-sr-only">Advertisement</span></label>
								</div>
													</div>
						<div class="cli-tab-content">
							<div class="cli-tab-pane cli-fade" data-id="advertisement">
								<div class="wt-cli-cookie-description">
									Advertisement cookies are used to provide visitors with relevant ads and marketing campaigns. These cookies track visitors across websites and collect information to provide customized ads.
								</div>
							</div>
						</div>
					</div>
																	<div class="cli-tab-section">
						<div class="cli-tab-header">
							<a role="button" tabindex="0" class="cli-nav-link cli-settings-mobile" data-target="others" data-toggle="cli-toggle-tab" data-original-title="" title="">
								Others							</a>
															<div class="cli-switch">
									<input type="checkbox" id="wt-cli-checkbox-others" class="cli-user-preference-checkbox" data-id="checkbox-others">
									<label for="wt-cli-checkbox-others" class="cli-slider" data-cli-enable="Enabled" data-cli-disable="Disabled"><span class="wt-cli-sr-only">Others</span></label>
								</div>
													</div>
						<div class="cli-tab-content">
							<div class="cli-tab-pane cli-fade" data-id="others">
								<div class="wt-cli-cookie-description">
									Other uncategorized cookies are those that are being analyzed and have not been classified into a category as yet.
								</div>
							</div>
						</div>
					</div>
										</div>
	</div>
</div>
		  </div>
		  <div class="cli-modal-footer">
			<div class="wt-cli-element cli-container-fluid cli-tab-container">
				<div class="cli-row">
					<div class="cli-col-12 cli-align-items-stretch cli-px-0">
						<div class="cli-tab-footer wt-cli-privacy-overview-actions">
						
															<a id="wt-cli-privacy-save-btn" role="button" tabindex="0" data-cli-action="accept" class="wt-cli-privacy-btn cli_setting_save_button wt-cli-privacy-accept-btn cli-btn">SAVE &amp; ACCEPT</a>
													</div>
						
					</div>
				</div>
			</div>
		</div>
	</div>
  </div>
</div>
<div class="cli-modal-backdrop cli-fade cli-settings-overlay"></div>
<div class="cli-modal-backdrop cli-fade cli-popupbar-overlay"></div>
<!--googleon: all--><style>.wp-container-1 > .alignleft { float: left; margin-inline-start: 0; margin-inline-end: 2em; }.wp-container-1 > .alignright { float: right; margin-inline-start: 2em; margin-inline-end: 0; }.wp-container-1 > .aligncenter { margin-left: auto !important; margin-right: auto !important; }</style>
		<div id="jp-carousel-loading-overlay">
			<div id="jp-carousel-loading-wrapper">
				<span id="jp-carousel-library-loading">&nbsp;</span>
			</div>
		</div>
		<div class="jp-carousel-overlay" style="display: none;">

		<div class="jp-carousel-container">
			<!-- The Carousel Swiper -->
			<div class="jp-carousel-wrap swiper-container jp-carousel-swiper-container jp-carousel-transitions" itemscope="" itemtype="https://schema.org/ImageGallery">
				<div class="jp-carousel swiper-wrapper"></div>
				<div class="jp-swiper-button-prev swiper-button-prev">
					<svg width="25" height="24" viewBox="0 0 25 24" fill="none" xmlns="http://www.w3.org/2000/svg">
						<mask id="maskPrev" mask-type="alpha" maskUnits="userSpaceOnUse" x="8" y="6" width="9" height="12">
							<path d="M16.2072 16.59L11.6496 12L16.2072 7.41L14.8041 6L8.8335 12L14.8041 18L16.2072 16.59Z" fill="white"></path>
						</mask>
						<g mask="url(#maskPrev)">
							<rect x="0.579102" width="23.8823" height="24" fill="#FFFFFF"></rect>
						</g>
					</svg>
				</div>
				<div class="jp-swiper-button-next swiper-button-next">
					<svg width="25" height="24" viewBox="0 0 25 24" fill="none" xmlns="http://www.w3.org/2000/svg">
						<mask id="maskNext" mask-type="alpha" maskUnits="userSpaceOnUse" x="8" y="6" width="8" height="12">
							<path d="M8.59814 16.59L13.1557 12L8.59814 7.41L10.0012 6L15.9718 12L10.0012 18L8.59814 16.59Z" fill="white"></path>
						</mask>
						<g mask="url(#maskNext)">
							<rect x="0.34375" width="23.8822" height="24" fill="#FFFFFF"></rect>
						</g>
					</svg>
				</div>
			</div>
			<!-- The main close buton -->
			<div class="jp-carousel-close-hint">
				<svg width="25" height="24" viewBox="0 0 25 24" fill="none" xmlns="http://www.w3.org/2000/svg">
					<mask id="maskClose" mask-type="alpha" maskUnits="userSpaceOnUse" x="5" y="5" width="15" height="14">
						<path d="M19.3166 6.41L17.9135 5L12.3509 10.59L6.78834 5L5.38525 6.41L10.9478 12L5.38525 17.59L6.78834 19L12.3509 13.41L17.9135 19L19.3166 17.59L13.754 12L19.3166 6.41Z" fill="white"></path>
					</mask>
					<g mask="url(#maskClose)">
						<rect x="0.409668" width="23.8823" height="24" fill="#FFFFFF"></rect>
					</g>
				</svg>
			</div>
			<!-- Image info, comments and meta -->
			<div class="jp-carousel-info">
				<div class="jp-carousel-info-footer">
					<div class="jp-carousel-pagination-container">
						<div class="jp-swiper-pagination swiper-pagination"></div>
						<div class="jp-carousel-pagination"></div>
					</div>
					<div class="jp-carousel-photo-title-container">
						<h2 class="jp-carousel-photo-caption"></h2>
					</div>
					<div class="jp-carousel-photo-icons-container">
						<a href="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial#" class="jp-carousel-icon-btn jp-carousel-icon-info" aria-label="Toggle photo metadata visibility">
							<span class="jp-carousel-icon">
								<svg width="25" height="24" viewBox="0 0 25 24" fill="none" xmlns="http://www.w3.org/2000/svg">
									<mask id="maskInfo" mask-type="alpha" maskUnits="userSpaceOnUse" x="2" y="2" width="21" height="20">
										<path fill-rule="evenodd" clip-rule="evenodd" d="M12.7537 2C7.26076 2 2.80273 6.48 2.80273 12C2.80273 17.52 7.26076 22 12.7537 22C18.2466 22 22.7046 17.52 22.7046 12C22.7046 6.48 18.2466 2 12.7537 2ZM11.7586 7V9H13.7488V7H11.7586ZM11.7586 11V17H13.7488V11H11.7586ZM4.79292 12C4.79292 16.41 8.36531 20 12.7537 20C17.142 20 20.7144 16.41 20.7144 12C20.7144 7.59 17.142 4 12.7537 4C8.36531 4 4.79292 7.59 4.79292 12Z" fill="white"></path>
									</mask>
									<g mask="url(#maskInfo)">
										<rect x="0.8125" width="23.8823" height="24" fill="#FFFFFF"></rect>
									</g>
								</svg>
							</span>
						</a>
												<a href="https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial#" class="jp-carousel-icon-btn jp-carousel-icon-comments" aria-label="Toggle photo comments visibility">
							<span class="jp-carousel-icon">
								<svg width="25" height="24" viewBox="0 0 25 24" fill="none" xmlns="http://www.w3.org/2000/svg">
									<mask id="maskComments" mask-type="alpha" maskUnits="userSpaceOnUse" x="2" y="2" width="21" height="20">
										<path fill-rule="evenodd" clip-rule="evenodd" d="M4.3271 2H20.2486C21.3432 2 22.2388 2.9 22.2388 4V16C22.2388 17.1 21.3432 18 20.2486 18H6.31729L2.33691 22V4C2.33691 2.9 3.2325 2 4.3271 2ZM6.31729 16H20.2486V4H4.3271V18L6.31729 16Z" fill="white"></path>
									</mask>
									<g mask="url(#maskComments)">
										<rect x="0.34668" width="23.8823" height="24" fill="#FFFFFF"></rect>
									</g>
								</svg>

								<span class="jp-carousel-has-comments-indicator" aria-label="This image has comments."></span>
							</span>
						</a>
											</div>
				</div>
				<div class="jp-carousel-info-extra">
					<div class="jp-carousel-info-content-wrapper">
						<div class="jp-carousel-photo-title-container">
							<h2 class="jp-carousel-photo-title"></h2>
						</div>
						<div class="jp-carousel-comments-wrapper">
															<div id="jp-carousel-comments-loading">
									<span>Loading Comments...</span>
								</div>
								<div class="jp-carousel-comments"></div>
								<div id="jp-carousel-comment-form-container">
									<span id="jp-carousel-comment-form-spinner">&nbsp;</span>
									<div id="jp-carousel-comment-post-results"></div>
																														<form id="jp-carousel-comment-form">
												<label for="jp-carousel-comment-form-comment-field" class="screen-reader-text">Write a Comment...</label>
												<textarea name="comment" class="jp-carousel-comment-form-field jp-carousel-comment-form-textarea" id="jp-carousel-comment-form-comment-field" placeholder="Write a Comment..."></textarea>
												<div id="jp-carousel-comment-form-submit-and-info-wrapper">
													<div id="jp-carousel-comment-form-commenting-as">
																													<fieldset>
																<label for="jp-carousel-comment-form-email-field">Email (Required)</label>
																<input type="text" name="email" class="jp-carousel-comment-form-field jp-carousel-comment-form-text-field" id="jp-carousel-comment-form-email-field">
															</fieldset>
															<fieldset>
																<label for="jp-carousel-comment-form-author-field">Name (Required)</label>
																<input type="text" name="author" class="jp-carousel-comment-form-field jp-carousel-comment-form-text-field" id="jp-carousel-comment-form-author-field">
															</fieldset>
															<fieldset>
																<label for="jp-carousel-comment-form-url-field">Website</label>
																<input type="text" name="url" class="jp-carousel-comment-form-field jp-carousel-comment-form-text-field" id="jp-carousel-comment-form-url-field">
															</fieldset>
																											</div>
													<input type="submit" name="submit" class="jp-carousel-comment-form-button" id="jp-carousel-comment-form-button-submit" value="Post Comment">
												</div>
											</form>
																											</div>
													</div>
						<div class="jp-carousel-image-meta">
							<div class="jp-carousel-title-and-caption">
								<div class="jp-carousel-photo-info">
									<h3 class="jp-carousel-caption" itemprop="caption description"></h3>
								</div>

								<div class="jp-carousel-photo-description"></div>
							</div>
							<ul class="jp-carousel-image-exif" style="display: none;"></ul>
							<a class="jp-carousel-image-download" target="_blank" style="display: none;">
								<svg width="25" height="24" viewBox="0 0 25 24" fill="none" xmlns="http://www.w3.org/2000/svg">
									<mask id="mask0" mask-type="alpha" maskUnits="userSpaceOnUse" x="3" y="3" width="19" height="18">
										<path fill-rule="evenodd" clip-rule="evenodd" d="M5.84615 5V19H19.7775V12H21.7677V19C21.7677 20.1 20.8721 21 19.7775 21H5.84615C4.74159 21 3.85596 20.1 3.85596 19V5C3.85596 3.9 4.74159 3 5.84615 3H12.8118V5H5.84615ZM14.802 5V3H21.7677V10H19.7775V6.41L9.99569 16.24L8.59261 14.83L18.3744 5H14.802Z" fill="white"></path>
									</mask>
									<g mask="url(#mask0)">
										<rect x="0.870605" width="23.8823" height="24" fill="#FFFFFF"></rect>
									</g>
								</svg>
								<span class="jp-carousel-download-text"></span>
							</a>
							<div class="jp-carousel-image-map" style="display: none;"></div>
						</div>
					</div>
				</div>
			</div>
		</div>

		</div>
		<link rel="stylesheet" id="blog-intext-cta-css" href="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/blog-intext-cta.css" type="text/css" media="all">
<link rel="stylesheet" id="separator-css" href="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/separator.css" type="text/css" media="all">
<link rel="stylesheet" id="medium-table-css" href="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/medium-table.css" type="text/css" media="all">
<link rel="stylesheet" id="author-new-format-box-css" href="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/author-new-format-box.css" type="text/css" media="all">
<link rel="stylesheet" id="button-css" href="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/button.css" type="text/css" media="all"><meta name="google-site-verification" content="HV7mAziXIZE7uHdEiuXiPv6eRLY4fifJqFVM671TABA">
<script type="text/javascript" id="">!function(b,e,f,g,a,c,d){b.fbq||(a=b.fbq=function(){a.callMethod?a.callMethod.apply(a,arguments):a.queue.push(arguments)},b._fbq||(b._fbq=a),a.push=a,a.loaded=!0,a.version="2.0",a.queue=[],c=e.createElement(f),c.async=!0,c.src=g,d=e.getElementsByTagName(f)[0],d.parentNode.insertBefore(c,d))}(window,document,"script","https://connect.facebook.net/en_US/fbevents.js");fbq("init","123046552428646");fbq("track","PageView");</script>
<noscript><img height="1" width="1" style="display:none" src="https://www.facebook.com/tr?id=123046552428646&amp;ev=PageView&amp;noscript=1"></noscript>

<link rel="stylesheet" id="cookie-law-info-table-css" href="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/cookie-law-info-table.css" type="text/css" media="all">
<script type="text/javascript" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/photon.min.js" id="jetpack-photon-js"></script>
<script type="text/javascript" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/index.js" id="swv-js"></script>
<script type="text/javascript" id="contact-form-7-js-extra">
/* <![CDATA[ */
var wpcf7 = {"api":{"root":"https:\/\/neptune.ai\/wp-json\/","namespace":"contact-form-7\/v1"},"cached":"1"};
/* ]]> */
</script>
<script type="text/javascript" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/index(1).js" id="contact-form-7-js"></script>
<script type="text/javascript" id="lbwps-photoswipe5-js-extra">
/* <![CDATA[ */
var lbwpsOptions = {"label_facebook":"Share on Facebook","label_twitter":"Tweet","label_pinterest":"Pin it","label_download":"Download image","label_copyurl":"Copy image URL","label_ui_close":"Close [Esc]","label_ui_zoom":"Zoom","label_ui_prev":"Previous [\u2190]","label_ui_next":"Next [\u2192]","label_ui_error":"The image cannot be loaded","label_ui_fullscreen":"Toggle fullscreen [F]","share_facebook":"1","share_twitter":"1","share_pinterest":"1","share_download":"1","share_direct":"0","share_copyurl":"0","close_on_drag":"1","history":"1","show_counter":"1","show_fullscreen":"1","show_zoom":"1","show_caption":"1","loop":"1","pinchtoclose":"1","taptotoggle":"1","close_on_click":"1","fulldesktop":"0","use_alt":"0","usecaption":"1","desktop_slider":"1","share_custom_label":"","share_custom_link":"","wheelmode":"close","spacing":"12","idletime":"4000","hide_scrollbars":"1","caption_type":"overlay"};
/* ]]> */
</script>
<script type="module" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/frontend.min.js"></script><script type="text/javascript" id="neptune-ajax-search-js-extra">
/* <![CDATA[ */
var neptune_ajax = {"ajaxurl":"https:\/\/neptune.ai\/wp-admin\/admin-ajax.php"};
/* ]]> */
</script>
<script type="text/javascript" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/suggest-words.js" id="neptune-ajax-search-js"></script>
<script type="text/javascript" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/jquery.min.js" id="jquery2-js"></script>
<script type="text/javascript" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/popper.min.js" id="popper.js-js"></script>
<script type="text/javascript" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/bootstrap.min.js" id="bootstrap-js"></script>
<script type="text/javascript" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/reading.js" id="reading-js"></script>
<script type="text/javascript" id="main-js-extra">
/* <![CDATA[ */
var main_obj = {"ajaxurl":"https:\/\/neptune.ai\/wp-admin\/admin-ajax.php","nonce":"ee6fa71e05"};
/* ]]> */
</script>
<script type="text/javascript" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/main.js" id="main-js"></script>
<script type="text/javascript" id="neptune-ajax-compare-js-extra">
/* <![CDATA[ */
var neptune_ajax = {"ajaxurl":"https:\/\/neptune.ai\/wp-admin\/admin-ajax.php"};
/* ]]> */
</script>
<script type="text/javascript" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/compare.js" id="neptune-ajax-compare-js"></script>
<script type="text/javascript" id="neptune-ajax-cf7-js-extra">
/* <![CDATA[ */
var neptune_ajax_cf7 = {"ajaxurl":"https:\/\/neptune.ai\/wp-admin\/admin-ajax.php"};
/* ]]> */
</script>
<script type="text/javascript" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/cf7.js" id="neptune-ajax-cf7-js"></script>
<script type="text/javascript" id="neptune-ajax-search-collect-js-extra">
/* <![CDATA[ */
var neptune_ajax_search_collect = {"ajaxurl":"https:\/\/neptune.ai\/wp-admin\/admin-ajax.php"};
/* ]]> */
</script>
<script type="text/javascript" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/search-collect.js" id="neptune-ajax-search-collect-js"></script>
<script type="text/javascript" id="neptune-ajax-resources-search-collect-js-extra">
/* <![CDATA[ */
var neptune_ajax_resources_search_collect = {"ajaxurl":"https:\/\/neptune.ai\/wp-admin\/admin-ajax.php"};
/* ]]> */
</script>
<script type="text/javascript" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/resources-search-collect.js" id="neptune-ajax-resources-search-collect-js"></script>
<script type="text/javascript" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/intersection-observer.js" id="jetpack-lazy-images-polyfill-intersectionobserver-js"></script>
<script type="text/javascript" id="jetpack-lazy-images-js-extra">
/* <![CDATA[ */
var jetpackLazyImagesL10n = {"loading_warning":"Images are still loading. Please cancel your print and try again."};
/* ]]> */
</script>
<script type="text/javascript" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/lazy-images.js" id="jetpack-lazy-images-js"></script>
<script type="text/javascript" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/api.js" id="google-recaptcha-js"></script>
<script type="text/javascript" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/regenerator-runtime.min.js" id="regenerator-runtime-js"></script>
<script type="text/javascript" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/wp-polyfill.min.js" id="wp-polyfill-js"></script>
<script type="text/javascript" id="wpcf7-recaptcha-js-extra">
/* <![CDATA[ */
var wpcf7_recaptcha = {"sitekey":"6LfTcaYfAAAAACV4WpHhqf1qGxfoL966ocQzuPXp","actions":{"homepage":"homepage","contactform":"contactform"}};
/* ]]> */
</script>
<script type="text/javascript" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/index(2).js" id="wpcf7-recaptcha-js"></script>
<script type="text/javascript" id="jetpack-carousel-js-extra">
/* <![CDATA[ */
var jetpackSwiperLibraryPath = {"url":"https:\/\/neptune.ai\/wp-content\/plugins\/jetpack\/_inc\/build\/carousel\/swiper-bundle.min.js"};
var jetpackCarouselStrings = {"widths":[370,700,1000,1200,1400,2000],"is_logged_in":"","lang":"en","ajaxurl":"https:\/\/neptune.ai\/wp-admin\/admin-ajax.php","nonce":"1132e8af32","display_exif":"1","display_comments":"1","single_image_gallery":"1","single_image_gallery_media_file":"","background_color":"black","comment":"Comment","post_comment":"Post Comment","write_comment":"Write a Comment...","loading_comments":"Loading Comments...","download_original":"View full size <span class=\"photo-size\">{0}<span class=\"photo-size-times\">\u00d7<\/span>{1}<\/span>","no_comment_text":"Please be sure to submit some text with your comment.","no_comment_email":"Please provide an email address to comment.","no_comment_author":"Please provide your name to comment.","comment_post_error":"Sorry, but there was an error posting your comment. Please try again later.","comment_approved":"Your comment was approved.","comment_unapproved":"Your comment is in moderation.","camera":"Camera","aperture":"Aperture","shutter_speed":"Shutter Speed","focal_length":"Focal Length","copyright":"Copyright","comment_registration":"0","require_name_email":"1","login_url":"https:\/\/neptune.ai\/wp-login.php?redirect_to=https%3A%2F%2Fneptune.ai%2Fblog%2Fhow-to-code-bert-using-pytorch-tutorial","blog_id":"1","meta_data":["camera","aperture","shutter_speed","focal_length","copyright"]};
/* ]]> */
</script>
<script type="text/javascript" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/jetpack-carousel.min.js" id="jetpack-carousel-js"></script>
<!-- Hotjar Tracking Code for neptune.ml -->
<script>
    (function(h,o,t,j,a,r){
        h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
        h._hjSettings={hjid:569747,hjsv:6};
        a=o.getElementsByTagName('head')[0];
        r=o.createElement('script');r.async=1;
        r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
        a.appendChild(r);
    })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
</script>

<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MZNL966"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->



<!-- Intercom integration -->
<script>
    /* !
   * JavaScript Cookie v2.2.1
   * https://github.com/js-cookie/js-cookie
   *
   * Copyright 2006, 2015 Klaus Hartl & Fagner Brack
   * Released under the MIT license
   *
   * Minified by jsDelivr using Terser v3.14.1.
   * Original file: /npm/js-cookie@2.2.1/src/js.cookie.js
   *
   * Do NOT use SRI with dynamically generated files! More information: https://www.jsdelivr.com/using-sri-with-dynamic-files
   */
    !function(e){var n;if("function"==typeof define&&define.amd&&(define(e),n=!0),"object"==typeof exports&&(module.exports=e(),n=!0),!n){var t=window.Cookies,o=window.Cookies=e();o.noConflict=function(){return window.Cookies=t,o}}}(function(){function e(){for(var e=0,n={};e<arguments.length;e++){var t=arguments[e];for(var o in t)n[o]=t[o]}return n}function n(e){return e.replace(/(%[0-9A-Z]{2})+/g,decodeURIComponent)}return function t(o){function r(){}function i(n,t,i){if("undefined"!=typeof document){"number"==typeof(i=e({path:"/"},r.defaults,i)).expires&&(i.expires=new Date(1*new Date+864e5*i.expires)),i.expires=i.expires?i.expires.toUTCString():"";try{var c=JSON.stringify(t);/^[\{\[]/.test(c)&&(t=c)}catch(e){}t=o.write?o.write(t,n):encodeURIComponent(String(t)).replace(/%(23|24|26|2B|3A|3C|3E|3D|2F|3F|40|5B|5D|5E|60|7B|7D|7C)/g,decodeURIComponent),n=encodeURIComponent(String(n)).replace(/%(23|24|26|2B|5E|60|7C)/g,decodeURIComponent).replace(/[\(\)]/g,escape);var f="";for(var u in i)i[u]&&(f+="; "+u,!0!==i[u]&&(f+="="+i[u].split(";")[0]));return document.cookie=n+"="+t+f}}function c(e,t){if("undefined"!=typeof document){for(var r={},i=document.cookie?document.cookie.split("; "):[],c=0;c<i.length;c++){var f=i[c].split("="),u=f.slice(1).join("=");t||'"'!==u.charAt(0)||(u=u.slice(1,-1));try{var a=n(f[0]);if(u=(o.read||o)(u,a)||n(u),t)try{u=JSON.parse(u)}catch(e){}if(r[a]=u,e===a)break}catch(e){}}return e?r[e]:r}}return r.set=i,r.get=function(e){return c(e,!1)},r.getJSON=function(e){return c(e,!0)},r.remove=function(n,t){i(n,"",e(t,{expires:-1}))},r.defaults={},r.withConverter=t,r}(function(){})});



    initIntercom(true);

    function initIntercom(isProduction) {
        var options = {
            devel: {
                appId: 'wqilukic',
            },
            prod: {
                appId: 'yoy39he9',
            },
        };

        var username = window.Cookies.get('neptune-uid');

        window.intercomSettings = {
            app_id: isProduction ? options.prod.appId : options.devel.appId,
        };

        var isUsernamePreserved = typeof username === 'string' && username.length > 0;
        if (isUsernamePreserved) {
            window.intercomSettings.user_id = username;
        }


        // Intercom official integration code }}}
        // eslint-disable-next-line
        (function(){var w=window;var ic=w.Intercom;if(typeof ic==="function"){ic('reattach_activator');ic('update',w.intercomSettings);}else{var d=document;var i=function(){i.c(arguments);};i.q=[];i.c=function(args){i.q.push(args);};w.Intercom=i;var l=function(){var s=d.createElement('script');s.type='text/javascript';s.async=true;s.src='https://widget.intercom.io/widget/wqilukic';var x=d.getElementsByTagName('script')[0];x.parentNode.insertBefore(s,x);};if(w.attachEvent){w.attachEvent('onload',l);}else{w.addEventListener('load',l,false);}}})();
        // Intercom official integration code {{{
    }

</script>
<!-- End of Intercom integration -->



<!-- Heap integration -->
<script type="text/javascript">   
window.heap=window.heap||[],heap.load=function(e,t){window.heap.appid=e,window.heap.config=t=t||{};var r=document.createElement("script");r.type="text/javascript",r.async=!0,r.src="https://cdn.heapanalytics.com/js/heap-"+e+".js";var a=document.getElementsByTagName("script")[0];a.parentNode.insertBefore(r,a);for(var n=function(e){return function(){heap.push([e].concat(Array.prototype.slice.call(arguments,0)))}},p=["addEventProperties","addUserProperties","clearEventProperties","identify","resetIdentity","removeEventProperty","setEventProperties","track","unsetEventProperty"],o=0;o<p.length;o++)heap[p[o]]=n(p[o])};   
heap.load("3102000718"); 
</script> 
<!-- End of Heap integration -->
<script>
try {
  const search = new URLSearchParams(window.location.search);
  if (search.has('chat-with-us') && typeof window.Intercom === 'function') {
      window.Intercom('show');
  }
} catch (e) {}
</script>	<script src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/e-202244.js" defer=""></script>
	<script>
		_stq = window._stq || [];
		_stq.push([ 'view', {v:'ext',blog:'158350742',post:'45909',tz:'1',srv:'neptune.ai',hp:'atomic',ac:'2',amp:'0',j:'1:11.5-beta4'} ]);
		_stq.push([ 'clickTrackerInit', '158350742', '45909' ]);
	</script>






<img src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/adsct" height="1" width="1" style="display: none;"><img src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/adsct(1)" height="1" width="1" style="display: none;"><div><div class="grecaptcha-badge" data-style="bottomright" style="width: 256px; height: 60px; display: block; transition: right 0.3s ease 0s; position: fixed; bottom: 14px; right: -186px; box-shadow: gray 0px 0px 5px; border-radius: 2px; overflow: hidden;"><div class="grecaptcha-logo"><iframe title="reCAPTCHA" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/anchor.html" width="256" height="60" role="presentation" name="a-ll4suxr12yf3" frameborder="0" scrolling="no" sandbox="allow-forms allow-popups allow-same-origin allow-scripts allow-top-navigation allow-modals allow-popups-to-escape-sandbox"></iframe></div><div class="grecaptcha-error"></div><textarea id="g-recaptcha-response-100000" name="g-recaptcha-response" class="g-recaptcha-response" style="width: 250px; height: 40px; border: 1px solid rgb(193, 193, 193); margin: 10px 25px; padding: 0px; resize: none; display: none;"></textarea></div><iframe style="display: none;" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/saved_resource.html"></iframe></div><iframe name="_hjRemoteVarsFrame" title="_hjRemoteVarsFrame" id="_hjRemoteVarsFrame" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/box-c1417f7b48595d0dbca01c86f95d6dbb.html" style="display: none !important; width: 1px !important; height: 1px !important; opacity: 0 !important; pointer-events: none !important;"></iframe><img src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/g.gif" alt="" width="6" height="5" id="wpstats"><iframe id="_hjSafeContext_94829783" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/saved_resource(1).html" style="display: none !important; width: 1px !important; height: 1px !important; opacity: 0 !important; pointer-events: none !important;"></iframe><iframe id="intercom-frame" style="position: absolute !important; opacity: 0 !important; width: 1px !important; height: 1px !important; top: 0 !important; left: 0 !important; border: none !important; display: block !important; z-index: -1 !important; pointer-events: none;" aria-hidden="true" tabindex="-1" title="Intercom" src="./How to Code BERT Using PyTorch - Tutorial With Examples - neptune.ai_files/saved_resource(2).html"></iframe><div class="intercom-lightweight-app"><div class="intercom-lightweight-app-launcher intercom-launcher" role="button" tabindex="0" aria-label="Open Intercom Messenger" aria-live="polite"><div class="intercom-lightweight-app-launcher-icon intercom-lightweight-app-launcher-icon-open"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 28 32"><path d="M28 32s-4.714-1.855-8.527-3.34H3.437C1.54 28.66 0 27.026 0 25.013V3.644C0 1.633 1.54 0 3.437 0h21.125c1.898 0 3.437 1.632 3.437 3.645v18.404H28V32zm-4.139-11.982a.88.88 0 00-1.292-.105c-.03.026-3.015 2.681-8.57 2.681-5.486 0-8.517-2.636-8.571-2.684a.88.88 0 00-1.29.107 1.01 1.01 0 00-.219.708.992.992 0 00.318.664c.142.128 3.537 3.15 9.762 3.15 6.226 0 9.621-3.022 9.763-3.15a.992.992 0 00.317-.664 1.01 1.01 0 00-.218-.707z"></path></svg></div><div class="intercom-lightweight-app-launcher-icon intercom-lightweight-app-launcher-icon-minimize"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path fill-rule="evenodd" clip-rule="evenodd" d="M18.601 8.39897C18.269 8.06702 17.7309 8.06702 17.3989 8.39897L12 13.7979L6.60099 8.39897C6.26904 8.06702 5.73086 8.06702 5.39891 8.39897C5.06696 8.73091 5.06696 9.2691 5.39891 9.60105L11.3989 15.601C11.7309 15.933 12.269 15.933 12.601 15.601L18.601 9.60105C18.9329 9.2691 18.9329 8.73091 18.601 8.39897Z" fill="white"></path>
</svg>
</div></div><style id="intercom-lightweight-app-style" type="text/css">
  @keyframes intercom-lightweight-app-launcher {
    from {
      opacity: 0;
      transform: scale(0.5);
    }
    to {
      opacity: 1;
      transform: scale(1);
    }
  }

  @keyframes intercom-lightweight-app-gradient {
    from {
      opacity: 0;
    }
    to {
      opacity: 1;
    }
  }

  @keyframes intercom-lightweight-app-messenger {
    
        0% {
          opacity: 0;
          transform: scale(0);
        }
        40% {
          opacity: 1;
        }
        100% {
          transform: scale(1);
        }
        
  }

  .intercom-lightweight-app {
    position: fixed;
    z-index: 2147483001;
    width: 0;
    height: 0;
    font-family: intercom-font, "Helvetica Neue", "Apple Color Emoji", Helvetica, Arial, sans-serif;
  }

  .intercom-lightweight-app-gradient {
    position: fixed;
    z-index: 2147483002;
    width: 500px;
    height: 500px;
    bottom: 0;
    right: 0;
    pointer-events: none;
    background: radial-gradient(
      ellipse at bottom right,
      rgba(29, 39, 54, 0.16) 0%,
      rgba(29, 39, 54, 0) 72%);
    animation: intercom-lightweight-app-gradient 200ms ease-out;
  }

  .intercom-lightweight-app-launcher {
    position: fixed;
    z-index: 2147483003;
    padding: 0 !important;
    margin: 0 !important;
    border: none;
    bottom: 20px;
    right: 20px;
    max-width: 48px;
    width: 48px;
    max-height: 48px;
    height: 48px;
    border-radius: 50%;
    background: #4455A6;
    cursor: pointer;
    box-shadow: 0 1px 6px 0 rgba(0, 0, 0, 0.06), 0 2px 32px 0 rgba(0, 0, 0, 0.16);
    transition: transform 167ms cubic-bezier(0.33, 0.00, 0.00, 1.00);
    box-sizing: content-box;
  }

  
        .intercom-lightweight-app-launcher:hover {
          transition: transform 250ms cubic-bezier(0.33, 0.00, 0.00, 1.00);
          transform: scale(1.1)
        }

        .intercom-lightweight-app-launcher:active {
          transform: scale(0.85);
          transition: transform 134ms cubic-bezier(0.45, 0, 0.2, 1);
        }
      


  .intercom-lightweight-app-launcher:focus {
    outline: none;

    
  }

  .intercom-lightweight-app-launcher-icon {
    display: flex;
    align-items: center;
    justify-content: center;
    position: absolute;
    top: 0;
    left: 0;
    width: 48px;
    height: 48px;
    transition: transform 100ms linear, opacity 80ms linear;
  }

  .intercom-lightweight-app-launcher-icon-open {
    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-open svg {
    width: 24px;
    height: 24px;
  }

  .intercom-lightweight-app-launcher-icon-open svg path {
    fill: rgb(255, 255, 255);
  }

  .intercom-lightweight-app-launcher-icon-self-serve {
    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-self-serve svg {
    height: 44px;
  }

  .intercom-lightweight-app-launcher-icon-self-serve svg path {
    fill: rgb(255, 255, 255);
  }

  .intercom-lightweight-app-launcher-custom-icon-open {
    max-height: 24px;
    max-width: 24px;

    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-minimize {
    
        opacity: 0;
        transform: rotate(-60deg) scale(0);
      
  }

  .intercom-lightweight-app-launcher-icon-minimize svg path {
    fill: rgb(255, 255, 255);
  }

  .intercom-lightweight-app-messenger {
    position: fixed;
    z-index: 2147483003;
    overflow: hidden;
    background-color: white;
    animation: intercom-lightweight-app-messenger 250ms cubic-bezier(0, 1.2, 1, 1);
    transform-origin: bottom right;
    
        width: 400px;
        height: calc(100% - 108px);
        max-height: 704px;
        min-height: 250px;
        right: 20px;
        bottom: 88px;
        box-shadow: 0 5px 40px rgba(0,0,0,0.16);
      
    border-radius: 15px;
  }

  .intercom-lightweight-app-messenger-header {
    height: 64px;
    background: #E5EAFF
  }

  .intercom-lightweight-app-messenger-footer{
    position:absolute;
    bottom:0;
    width: 100%;
    min-height: 81px;
    background: #fff;
    font-size: 14px;
    line-height: 21px;
    border-top: 1px solid rgba(0, 0, 0, 0.05);
    box-shadow: 0px 0px 25px rgba(0, 0, 0, 0.05);
  }

  @media print {
    .intercom-lightweight-app {
      display: none;
    }
  }
</style></div></body></html>